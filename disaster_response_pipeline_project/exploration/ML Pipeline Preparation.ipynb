{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/conda/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys; sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-multilearn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/1f/e6ff649c72a1cdf2c7a1d31eb21705110ce1c5d3e7e26b2cc300e1637272/scikit_multilearn-0.2.0-py3-none-any.whl (89kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 3.5MB/s ta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
      "Successfully installed scikit-multilearn-0.2.0\n",
      "Collecting arff\n",
      "  Downloading https://files.pythonhosted.org/packages/50/de/62d4446c5a6e459052c2f2d9490c370ddb6abc0766547b4cef585913598d/arff-0.9.tar.gz\n",
      "Building wheels for collected packages: arff\n",
      "  Running setup.py bdist_wheel for arff ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/04/d0/70/2c73afedd3ac25c6085b528742c69b9587cbdfa67e5194583b\n",
      "Successfully built arff\n",
      "Installing collected packages: arff\n",
      "Successfully installed arff-0.9\n"
     ]
    }
   ],
   "source": [
    "! {sys.executable} -m pip install scikit-multilearn\n",
    "! {sys.executable} -m pip install arff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from skmultilearn.model_selection import iterative_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterMessages.db')\n",
    "df = pd.read_sql('SELECT * FROM CleanMessages', engine)\n",
    "\n",
    "# define variables. X is input, Y is target\n",
    "X = df['message']\n",
    "Y = df.drop(['id', 'message', 'original', 'genre'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the 'child alone' tag because there are no messages with this tag.\n",
    "Y = Y.drop('child_alone', axis=1)\n",
    "\n",
    "# replace 2's with 1's in the related field\n",
    "Y.loc[Y.related == 2, 'related'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26216,), (26216, 35))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the shape of the data\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 26k messages with 35 possible labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that will allow a treebank POS tag to be converted into a WordNet\n",
    "# POS Tag so the lemmatizer will understand it\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    # default to Noun \n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    # remove all non-alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    \n",
    "    # lower and strip whitespace\n",
    "    text = text.lower().strip()\n",
    "    \n",
    "    # tokenize words\n",
    "    words = word_tokenize(text)\n",
    "        \n",
    "    # tag words with Part of Speech - list of (word, POS) tuples \n",
    "    words_with_pos_tag = pos_tag(words)\n",
    "    \n",
    "    # remove stop words\n",
    "    words_with_pos_tag = [word for word in words_with_pos_tag if word[0] not in stop_words]\n",
    "    \n",
    "    # change pos tags to wordnet pos tags for lemmatizer\n",
    "    words_with_wordnet_tag = []\n",
    "    \n",
    "    for word_with_tag in words_with_pos_tag:\n",
    "        word, tag = word_with_tag\n",
    "        tag = get_wordnet_pos(tag)\n",
    "        words_with_wordnet_tag.append((word, tag))\n",
    "\n",
    "    # lemmatize\n",
    "    lemm = WordNetLemmatizer()\n",
    "    # unpack the (word, pos) tuple into the Lemmatizer to give better lemmatization\n",
    "    words = [lemm.lemmatize(*w) for w in words_with_wordnet_tag]\n",
    "    \n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a custom transformer to determine if removing stops and/or lemmatizing improves model performance\n",
    "\n",
    "class MessageTokenizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, remove_stops=True, lemmatize=True):\n",
    "        self.remove_stops = remove_stops\n",
    "        self.lemmatize = lemmatize\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        \n",
    "        # iterate over supplied messages\n",
    "        for text in X: \n",
    "            # remove all non-alphanumeric characters\n",
    "            text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    \n",
    "            # lower and strip whitespace\n",
    "            text = text.lower().strip()\n",
    "    \n",
    "            # tokenize words - nltk.tokenize.word_tokenize\n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.lemmatize:\n",
    "                # tag words with Part of Speech - list of (word, POS) tuples \n",
    "                # nltk.pos_tag()\n",
    "                words_with_pos_tag = pos_tag(words)\n",
    "                \n",
    "                if self.remove_stops:\n",
    "                    # remove stop words\n",
    "                    # stop_words = nlt.corpus.stopwords of 'english' language\n",
    "                    words_with_pos_tag = [word for word in words_with_pos_tag if word[0] not in stop_words]\n",
    "                \n",
    "                # change pos tags to wordnet pos tags for lemmatizer\n",
    "                words_with_wordnet_tag = []\n",
    "    \n",
    "                for word_with_tag in words_with_pos_tag:\n",
    "                    word, tag = word_with_tag\n",
    "                    tag = get_wordnet_pos(tag)\n",
    "                    words_with_wordnet_tag.append((word, tag))\n",
    "\n",
    "                # lemmatize\n",
    "                lemm = WordNetLemmatizer()\n",
    "                # unpack the (word, pos) tuple into the Lemmatizer to give better lemmatization\n",
    "                words = [lemm.lemmatize(*w) for w in words_with_wordnet_tag]\n",
    "                \n",
    "            else:\n",
    "                if self.remove_stops:\n",
    "                    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "            # join cleaned words back into single document\n",
    "            X_transformed.append(' '.join(words))\n",
    "        \n",
    "        return X_transformed    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"We would not want these words taking up space in our database, or taking up valuable processing time. For this, we can remove them easily, by storing a list of words that you consider to be stop words\"]\n",
    "text.append(\"Here is another example of words. Isn't it great how words are?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['would want word take space database take valuable processing time remove easily store list word consider stop word',\n",
       " 'another example word great word']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MessageTokenizer(remove_stops=True, lemmatize=True).transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('msg_tokenizer', MessageTokenizer()),\n",
    "    # Count Vectorizer with Tokenizer\n",
    "    ('count_vec', CountVectorizer(tokenizer=tokenize)),\n",
    "    # TF-IDF Transformer\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # classifier - one classifier per label\n",
    "    ('clf', MultiOutputClassifier(estimator=RandomForestClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a multilabel classification, I looked into the iterative train-test-split supplied by skmultilearn.\n",
    "Here I will compare whether this train test split results in appropriate label representation for the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the proportion of labels in the original data\n",
    "compare = pd.DataFrame(Y.mean(axis=0), columns=['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.773650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.170659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.004501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.414251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.079493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset\n",
       "related       0.773650\n",
       "request       0.170659\n",
       "offer         0.004501\n",
       "aid_related   0.414251\n",
       "medical_help  0.079493"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employ skmultilearn's iterative train test split.\n",
    "# have to reshape the X values to be multidimensional since that's what this expects\n",
    "\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X.values.reshape(-1,1), Y.values, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to see how the iterative split did with label proportions\n",
    "compare['train_set'] = y_train.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal train test split - how does it compare\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare['normal_split'] = y_train2.values.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train_set</th>\n",
       "      <th>normal_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.773650</td>\n",
       "      <td>0.771488</td>\n",
       "      <td>0.775201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.170659</td>\n",
       "      <td>0.135795</td>\n",
       "      <td>0.170990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>0.004476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.414251</td>\n",
       "      <td>0.414251</td>\n",
       "      <td>0.413997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.079493</td>\n",
       "      <td>0.086919</td>\n",
       "      <td>0.079595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.050084</td>\n",
       "      <td>0.054165</td>\n",
       "      <td>0.049842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.027617</td>\n",
       "      <td>0.028837</td>\n",
       "      <td>0.028176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.017966</td>\n",
       "      <td>0.019225</td>\n",
       "      <td>0.017191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.032804</td>\n",
       "      <td>0.041857</td>\n",
       "      <td>0.032499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.063778</td>\n",
       "      <td>0.062710</td>\n",
       "      <td>0.062557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.111497</td>\n",
       "      <td>0.099125</td>\n",
       "      <td>0.112654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.088267</td>\n",
       "      <td>0.084834</td>\n",
       "      <td>0.087784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.015449</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.015665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.023039</td>\n",
       "      <td>0.024514</td>\n",
       "      <td>0.022378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.011367</td>\n",
       "      <td>0.011189</td>\n",
       "      <td>0.011189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.033377</td>\n",
       "      <td>0.037890</td>\n",
       "      <td>0.033059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.045545</td>\n",
       "      <td>0.049588</td>\n",
       "      <td>0.045875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.131446</td>\n",
       "      <td>0.124402</td>\n",
       "      <td>0.132031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.065037</td>\n",
       "      <td>0.068457</td>\n",
       "      <td>0.064439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.045812</td>\n",
       "      <td>0.048317</td>\n",
       "      <td>0.044756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.050860</td>\n",
       "      <td>0.049385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.020293</td>\n",
       "      <td>0.020293</td>\n",
       "      <td>0.018665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.006065</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>0.006256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.010795</td>\n",
       "      <td>0.011901</td>\n",
       "      <td>0.010884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.004425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.011787</td>\n",
       "      <td>0.012867</td>\n",
       "      <td>0.012003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.043904</td>\n",
       "      <td>0.046282</td>\n",
       "      <td>0.043129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.278341</td>\n",
       "      <td>0.278354</td>\n",
       "      <td>0.278456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.082202</td>\n",
       "      <td>0.093480</td>\n",
       "      <td>0.082901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.093187</td>\n",
       "      <td>0.092869</td>\n",
       "      <td>0.092157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.010757</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>0.010681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.093645</td>\n",
       "      <td>0.081528</td>\n",
       "      <td>0.092564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.020217</td>\n",
       "      <td>0.021615</td>\n",
       "      <td>0.019835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.052487</td>\n",
       "      <td>0.057827</td>\n",
       "      <td>0.052487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.193584</td>\n",
       "      <td>0.157970</td>\n",
       "      <td>0.193419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         dataset  train_set  normal_split\n",
       "related                 0.773650   0.771488      0.775201\n",
       "request                 0.170659   0.135795      0.170990\n",
       "offer                   0.004501   0.004526      0.004476\n",
       "aid_related             0.414251   0.414251      0.413997\n",
       "medical_help            0.079493   0.086919      0.079595\n",
       "medical_products        0.050084   0.054165      0.049842\n",
       "search_and_rescue       0.027617   0.028837      0.028176\n",
       "security                0.017966   0.019225      0.017191\n",
       "military                0.032804   0.041857      0.032499\n",
       "water                   0.063778   0.062710      0.062557\n",
       "food                    0.111497   0.099125      0.112654\n",
       "shelter                 0.088267   0.084834      0.087784\n",
       "clothing                0.015449   0.013274      0.015665\n",
       "money                   0.023039   0.024514      0.022378\n",
       "missing_people          0.011367   0.011189      0.011189\n",
       "refugees                0.033377   0.037890      0.033059\n",
       "death                   0.045545   0.049588      0.045875\n",
       "other_aid               0.131446   0.124402      0.132031\n",
       "infrastructure_related  0.065037   0.068457      0.064439\n",
       "transport               0.045812   0.048317      0.044756\n",
       "buildings               0.050847   0.050860      0.049385\n",
       "electricity             0.020293   0.020293      0.018665\n",
       "tools                   0.006065   0.006408      0.006256\n",
       "hospitals               0.010795   0.011901      0.010884\n",
       "shops                   0.004577   0.004476      0.004425\n",
       "aid_centers             0.011787   0.012867      0.012003\n",
       "other_infrastructure    0.043904   0.046282      0.043129\n",
       "weather_related         0.278341   0.278354      0.278456\n",
       "floods                  0.082202   0.093480      0.082901\n",
       "storm                   0.093187   0.092869      0.092157\n",
       "fire                    0.010757   0.011799      0.010681\n",
       "earthquake              0.093645   0.081528      0.092564\n",
       "cold                    0.020217   0.021615      0.019835\n",
       "other_weather           0.052487   0.057827      0.052487\n",
       "direct_report           0.193584   0.157970      0.193419"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset - normalsplit</th>\n",
       "      <th>dataset - iterative split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>-0.001551</td>\n",
       "      <td>0.002162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>-0.000331</td>\n",
       "      <td>0.034864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>-0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.007425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.000242</td>\n",
       "      <td>-0.004081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>-0.000559</td>\n",
       "      <td>-0.001221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.000776</td>\n",
       "      <td>-0.001259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>-0.009053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.001068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>-0.001157</td>\n",
       "      <td>0.012372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.003433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>-0.000216</td>\n",
       "      <td>0.002174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.000661</td>\n",
       "      <td>-0.001475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.000318</td>\n",
       "      <td>-0.004514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>-0.000331</td>\n",
       "      <td>-0.004043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>-0.000585</td>\n",
       "      <td>0.007044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.000598</td>\n",
       "      <td>-0.003420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.001055</td>\n",
       "      <td>-0.002505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.001462</td>\n",
       "      <td>-0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>-0.000191</td>\n",
       "      <td>-0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>-0.000089</td>\n",
       "      <td>-0.001106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>-0.000216</td>\n",
       "      <td>-0.001081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.000776</td>\n",
       "      <td>-0.002378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>-0.000699</td>\n",
       "      <td>-0.011278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.000076</td>\n",
       "      <td>-0.001043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.012117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.000381</td>\n",
       "      <td>-0.001399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.035614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        dataset - normalsplit  dataset - iterative split\n",
       "related                             -0.001551                   0.002162\n",
       "request                             -0.000331                   0.034864\n",
       "offer                                0.000025                  -0.000025\n",
       "aid_related                          0.000254                   0.000000\n",
       "medical_help                        -0.000102                  -0.007425\n",
       "medical_products                     0.000242                  -0.004081\n",
       "search_and_rescue                   -0.000559                  -0.001221\n",
       "security                             0.000776                  -0.001259\n",
       "military                             0.000305                  -0.009053\n",
       "water                                0.001221                   0.001068\n",
       "food                                -0.001157                   0.012372\n",
       "shelter                              0.000483                   0.003433\n",
       "clothing                            -0.000216                   0.002174\n",
       "money                                0.000661                  -0.001475\n",
       "missing_people                       0.000178                   0.000178\n",
       "refugees                             0.000318                  -0.004514\n",
       "death                               -0.000331                  -0.004043\n",
       "other_aid                           -0.000585                   0.007044\n",
       "infrastructure_related               0.000598                  -0.003420\n",
       "transport                            0.001055                  -0.002505\n",
       "buildings                            0.001462                  -0.000013\n",
       "electricity                          0.001628                   0.000000\n",
       "tools                               -0.000191                  -0.000343\n",
       "hospitals                           -0.000089                  -0.001106\n",
       "shops                                0.000153                   0.000102\n",
       "aid_centers                         -0.000216                  -0.001081\n",
       "other_infrastructure                 0.000776                  -0.002378\n",
       "weather_related                     -0.000114                  -0.000013\n",
       "floods                              -0.000699                  -0.011278\n",
       "storm                                0.001030                   0.000318\n",
       "fire                                 0.000076                  -0.001043\n",
       "earthquake                           0.001081                   0.012117\n",
       "cold                                 0.000381                  -0.001399\n",
       "other_weather                        0.000000                  -0.005340\n",
       "direct_report                        0.000165                   0.035614"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = pd.DataFrame(compare['dataset'] - compare['normal_split'])\n",
    "diff.columns = ['dataset - normalsplit']\n",
    "diff['dataset - iterative split'] = compare['dataset'] - compare['train_set']\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that a normal train-test-split does a fine job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('msg_tokenizer', MessageTokenizer(lemmatize=True, remove_stops=True)), ('count_vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MessageTokenizer(remove_stops=True, lemmatize=True).transform(X_train.reshape(-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      4556\n",
      "          1       1.00      0.99      0.99     14986\n",
      "          2       0.88      0.99      0.93       120\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "request \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     16548\n",
      "          1       0.92      1.00      0.96      3114\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "offer \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19604\n",
      "          1       0.62      1.00      0.77        58\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "aid_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     11733\n",
      "          1       0.97      0.99      0.98      7929\n",
      "\n",
      "avg / total       0.98      0.98      0.98     19662\n",
      "\n",
      "medical_help \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99     18306\n",
      "          1       0.86      1.00      0.92      1356\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "medical_products \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     18831\n",
      "          1       0.83      1.00      0.91       831\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "search_and_rescue \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     19205\n",
      "          1       0.82      1.00      0.90       457\n",
      "\n",
      "avg / total       1.00      0.99      1.00     19662\n",
      "\n",
      "security \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19404\n",
      "          1       0.73      1.00      0.85       258\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "military \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19089\n",
      "          1       0.87      1.00      0.93       573\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "water \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     18485\n",
      "          1       0.93      1.00      0.96      1177\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "food \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     17569\n",
      "          1       0.95      1.00      0.97      2093\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "shelter \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     18072\n",
      "          1       0.91      1.00      0.95      1590\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "clothing \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19399\n",
      "          1       0.84      1.00      0.91       263\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "money \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19294\n",
      "          1       0.83      1.00      0.91       368\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "missing_people \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19498\n",
      "          1       0.77      0.99      0.87       164\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "refugees \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     19101\n",
      "          1       0.84      1.00      0.91       561\n",
      "\n",
      "avg / total       1.00      0.99      0.99     19662\n",
      "\n",
      "death \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     18892\n",
      "          1       0.85      1.00      0.92       770\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "other_aid \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     17471\n",
      "          1       0.84      1.00      0.91      2191\n",
      "\n",
      "avg / total       0.98      0.98      0.98     19662\n",
      "\n",
      "infrastructure_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     18680\n",
      "          1       0.77      1.00      0.87       982\n",
      "\n",
      "avg / total       0.99      0.98      0.99     19662\n",
      "\n",
      "transport \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     18915\n",
      "          1       0.82      1.00      0.90       747\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "buildings \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     18801\n",
      "          1       0.87      1.00      0.93       861\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "electricity \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19331\n",
      "          1       0.82      1.00      0.90       331\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "tools \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19575\n",
      "          1       0.70      1.00      0.82        87\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "hospitals \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19487\n",
      "          1       0.80      1.00      0.89       175\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "shops \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19597\n",
      "          1       0.76      1.00      0.86        65\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "aid_centers \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19495\n",
      "          1       0.73      1.00      0.84       167\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "other_infrastructure \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99     19009\n",
      "          1       0.76      1.00      0.86       653\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "weather_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     14450\n",
      "          1       0.96      1.00      0.98      5212\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "floods \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     18205\n",
      "          1       0.91      1.00      0.95      1457\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "storm \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     17951\n",
      "          1       0.94      1.00      0.96      1711\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "fire \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19477\n",
      "          1       0.84      1.00      0.91       185\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "earthquake \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     17919\n",
      "          1       0.96      1.00      0.98      1743\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "cold \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19318\n",
      "          1       0.86      1.00      0.92       344\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "other_weather \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99     18793\n",
      "          1       0.82      1.00      0.90       869\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "direct_report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     16239\n",
      "          1       0.90      1.00      0.95      3423\n",
      "\n",
      "avg / total       0.98      0.98      0.98     19662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = pd.DataFrame(y_pred, columns=Y.columns)\n",
    "y_train = pd.DataFrame(y_train, columns=Y.columns)\n",
    "\n",
    "for col in Y.columns:\n",
    "    print(col, '\\n', classification_report(y_pred[col], y_train[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-eada1d6fb183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# drop related column while measuring this because there are some rows with related=2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhamming_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'related'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'related'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# compute hamming loss as well\n",
    "from sklearn.metrics import hamming_loss, make_scorer\n",
    "hamming_scorer = make_scorer(hamming_loss, greater_is_better=False)\n",
    "\n",
    "# drop related column while measuring this because there are some rows with related=2\n",
    "hamming_loss(y_train.drop('related', axis=1), y_pred.drop('related', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('msg_tokenizer', MessageTokenizer(lemmatize=True, remove_stops=True)), ('count_vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit and predict on the iterative split to see if it performs better\n",
    "pipeline2 = Pipeline([\n",
    "    ('msg_tokenizer', MessageTokenizer()),\n",
    "    # Count Vectorizer with Tokenizer\n",
    "    ('count_vec', CountVectorizer(tokenizer=tokenize)),\n",
    "    # TF-IDF Transformer\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # classifier - one classifier per label\n",
    "    ('clf', MultiOutputClassifier(estimator=RandomForestClassifier()))\n",
    "])\n",
    "\n",
    "X_train2, y_train2, X_test2, y_test2 = iterative_train_test_split(X.values.reshape(-1,1), Y.values, test_size = 0.25)\n",
    "\n",
    "pipeline2.fit(X_train.values.reshape(-1,), y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.93      0.90      4269\n",
      "          1       0.98      0.96      0.97     15316\n",
      "          2       0.71      0.94      0.80        77\n",
      "\n",
      "avg / total       0.95      0.95      0.95     19662\n",
      "\n",
      "request \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98     17519\n",
      "          1       0.78      0.96      0.86      2143\n",
      "\n",
      "avg / total       0.97      0.97      0.97     19662\n",
      "\n",
      "offer \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19620\n",
      "          1       0.48      1.00      0.65        42\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "aid_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.91      0.94     12143\n",
      "          1       0.87      0.94      0.90      7519\n",
      "\n",
      "avg / total       0.93      0.92      0.92     19662\n",
      "\n",
      "medical_help \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98     18465\n",
      "          1       0.68      0.97      0.80      1197\n",
      "\n",
      "avg / total       0.98      0.97      0.97     19662\n",
      "\n",
      "medical_products \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     18996\n",
      "          1       0.64      0.99      0.78       666\n",
      "\n",
      "avg / total       0.99      0.98      0.98     19662\n",
      "\n",
      "search_and_rescue \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99     19270\n",
      "          1       0.67      0.97      0.79       392\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "security \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     19457\n",
      "          1       0.54      1.00      0.70       205\n",
      "\n",
      "avg / total       1.00      0.99      0.99     19662\n",
      "\n",
      "military \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99     19086\n",
      "          1       0.69      0.98      0.81       576\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "water \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     18742\n",
      "          1       0.74      0.98      0.85       920\n",
      "\n",
      "avg / total       0.99      0.98      0.98     19662\n",
      "\n",
      "food \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     18081\n",
      "          1       0.81      0.98      0.89      1581\n",
      "\n",
      "avg / total       0.98      0.98      0.98     19662\n",
      "\n",
      "shelter \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     18388\n",
      "          1       0.75      0.97      0.84      1274\n",
      "\n",
      "avg / total       0.98      0.98      0.98     19662\n",
      "\n",
      "clothing \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     19488\n",
      "          1       0.63      0.99      0.77       174\n",
      "\n",
      "avg / total       1.00      0.99      1.00     19662\n",
      "\n",
      "money \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     19381\n",
      "          1       0.60      1.00      0.75       281\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "missing_people \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     19542\n",
      "          1       0.54      0.99      0.70       120\n",
      "\n",
      "avg / total       1.00      0.99      1.00     19662\n",
      "\n",
      "refugees \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99     19158\n",
      "          1       0.67      0.99      0.80       504\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "death \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     18990\n",
      "          1       0.68      0.99      0.81       672\n",
      "\n",
      "avg / total       0.99      0.98      0.99     19662\n",
      "\n",
      "other_aid \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97     18054\n",
      "          1       0.64      0.97      0.77      1608\n",
      "\n",
      "avg / total       0.97      0.95      0.96     19662\n",
      "\n",
      "infrastructure_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98     18872\n",
      "          1       0.58      0.99      0.73       790\n",
      "\n",
      "avg / total       0.98      0.97      0.97     19662\n",
      "\n",
      "transport \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     19018\n",
      "          1       0.66      0.97      0.78       644\n",
      "\n",
      "avg / total       0.99      0.98      0.98     19662\n",
      "\n",
      "buildings \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     18978\n",
      "          1       0.67      0.98      0.79       684\n",
      "\n",
      "avg / total       0.99      0.98      0.98     19662\n",
      "\n",
      "electricity \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     19397\n",
      "          1       0.66      0.99      0.79       265\n",
      "\n",
      "avg / total       1.00      0.99      0.99     19662\n",
      "\n",
      "tools \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19593\n",
      "          1       0.54      1.00      0.70        69\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "hospitals \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19518\n",
      "          1       0.61      1.00      0.76       144\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "shops \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19610\n",
      "          1       0.56      1.00      0.72        52\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "aid_centers \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     19519\n",
      "          1       0.56      1.00      0.72       143\n",
      "\n",
      "avg / total       1.00      0.99      1.00     19662\n",
      "\n",
      "other_infrastructure \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     19138\n",
      "          1       0.57      0.99      0.72       524\n",
      "\n",
      "avg / total       0.99      0.98      0.98     19662\n",
      "\n",
      "weather_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.95      0.97     14756\n",
      "          1       0.87      0.97      0.92      4906\n",
      "\n",
      "avg / total       0.96      0.96      0.96     19662\n",
      "\n",
      "floods \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     18149\n",
      "          1       0.81      0.98      0.89      1513\n",
      "\n",
      "avg / total       0.98      0.98      0.98     19662\n",
      "\n",
      "storm \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     18117\n",
      "          1       0.81      0.95      0.88      1545\n",
      "\n",
      "avg / total       0.98      0.98      0.98     19662\n",
      "\n",
      "fire \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19506\n",
      "          1       0.68      0.99      0.80       156\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "earthquake \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99     18197\n",
      "          1       0.88      0.96      0.92      1465\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "cold \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     19382\n",
      "          1       0.64      1.00      0.78       280\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "other_weather \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     18868\n",
      "          1       0.66      0.96      0.79       794\n",
      "\n",
      "avg / total       0.98      0.98      0.98     19662\n",
      "\n",
      "direct_report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.95      0.97     17300\n",
      "          1       0.73      0.96      0.83      2362\n",
      "\n",
      "avg / total       0.96      0.95      0.95     19662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = pipeline.predict(X_train2.reshape(-1,))\n",
    "y_pred2 = pd.DataFrame(y_pred2, columns=Y.columns)\n",
    "y_train2 = pd.DataFrame(y_train2, columns=Y.columns)\n",
    "\n",
    "for col in Y.columns:\n",
    "    print(col, '\\n', classification_report(y_pred2[col], y_train2[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018713313827209248"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop related column while measuring this because there are some rows with related=2\n",
    "hamming_loss(y_train2.drop('related', axis=1), y_pred2.drop('related', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, doesn't seem to be any advantage to it - precision is lower and hamming loss is higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>water</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15196</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11247</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25764</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17534</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12025</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12249</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13632</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11617</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18124</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7892</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5598</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22156</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11417</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6615</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12121</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12191</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10492</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22400</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11315</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11514</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13501</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25179</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23584</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20608</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16931</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20666</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25060</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15489</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15775</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18405</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12135</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25516</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25495</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6479</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13475</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15955</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16180</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22028</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12527</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9624</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13798</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25590</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19662 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "15196        1        0      0            1             0                 0   \n",
       "11247        1        0      0            0             0                 0   \n",
       "844          1        1      0            1             0                 0   \n",
       "1392         0        0      0            0             0                 0   \n",
       "25764        0        0      0            0             0                 0   \n",
       "9090         1        0      0            1             0                 0   \n",
       "47           1        1      0            1             0                 0   \n",
       "17534        1        0      0            1             0                 0   \n",
       "1732         0        0      0            0             0                 0   \n",
       "12025        0        0      0            0             0                 0   \n",
       "12249        1        1      0            1             0                 0   \n",
       "13632        1        0      0            1             0                 0   \n",
       "11617        1        0      0            0             0                 0   \n",
       "18124        1        0      0            1             0                 0   \n",
       "5786         1        0      0            0             0                 0   \n",
       "7892         0        0      0            0             0                 0   \n",
       "5598         1        0      0            0             0                 0   \n",
       "22156        1        0      0            1             0                 0   \n",
       "11417        1        0      0            0             0                 0   \n",
       "6615         0        0      0            0             0                 0   \n",
       "12121        2        0      0            0             0                 0   \n",
       "2762         1        1      0            1             0                 0   \n",
       "18347        1        0      0            1             0                 0   \n",
       "1063         1        1      0            1             0                 0   \n",
       "12191        1        1      0            1             0                 0   \n",
       "10492        1        0      0            0             0                 0   \n",
       "821          1        1      0            1             0                 0   \n",
       "22400        0        0      0            0             0                 0   \n",
       "11315        0        0      0            0             0                 0   \n",
       "11514        1        0      0            1             0                 0   \n",
       "...        ...      ...    ...          ...           ...               ...   \n",
       "13501        1        0      0            0             0                 0   \n",
       "1432         0        0      0            0             0                 0   \n",
       "1307         1        0      0            0             0                 0   \n",
       "25179        1        0      0            1             1                 1   \n",
       "23584        1        0      0            1             0                 0   \n",
       "189          1        1      0            1             0                 0   \n",
       "20608        1        0      0            0             0                 0   \n",
       "3657         1        0      0            0             0                 0   \n",
       "16931        1        0      0            1             0                 0   \n",
       "20666        1        0      0            0             0                 0   \n",
       "25060        0        0      0            0             0                 0   \n",
       "1389         0        0      0            0             0                 0   \n",
       "20237        0        0      0            0             0                 0   \n",
       "15489        0        0      0            0             0                 0   \n",
       "15775        1        0      0            1             0                 0   \n",
       "3789         1        0      0            0             0                 0   \n",
       "18405        1        0      0            1             0                 0   \n",
       "12135        1        0      0            0             0                 0   \n",
       "25516        1        0      0            0             0                 0   \n",
       "25495        1        0      0            0             0                 0   \n",
       "6479         1        0      0            0             0                 0   \n",
       "13475        1        0      0            1             0                 0   \n",
       "15955        0        0      0            0             0                 0   \n",
       "16180        1        0      0            1             0                 0   \n",
       "22028        1        0      0            1             0                 0   \n",
       "12527        1        0      0            1             0                 0   \n",
       "9624         1        0      0            0             0                 0   \n",
       "13798        1        0      0            0             0                 0   \n",
       "1350         1        1      0            1             0                 0   \n",
       "25590        1        0      0            0             0                 0   \n",
       "\n",
       "       search_and_rescue  security  military  water      ...        \\\n",
       "15196                  0         0         0      0      ...         \n",
       "11247                  0         0         0      0      ...         \n",
       "844                    0         0         0      1      ...         \n",
       "1392                   0         0         0      0      ...         \n",
       "25764                  0         0         0      0      ...         \n",
       "9090                   0         0         0      0      ...         \n",
       "47                     0         0         0      0      ...         \n",
       "17534                  0         0         0      0      ...         \n",
       "1732                   0         0         0      0      ...         \n",
       "12025                  0         0         0      0      ...         \n",
       "12249                  0         0         0      0      ...         \n",
       "13632                  0         0         0      1      ...         \n",
       "11617                  0         0         0      0      ...         \n",
       "18124                  0         0         0      0      ...         \n",
       "5786                   0         0         0      0      ...         \n",
       "7892                   0         0         0      0      ...         \n",
       "5598                   0         0         0      0      ...         \n",
       "22156                  0         0         0      0      ...         \n",
       "11417                  0         0         0      0      ...         \n",
       "6615                   0         0         0      0      ...         \n",
       "12121                  0         0         0      0      ...         \n",
       "2762                   0         0         0      0      ...         \n",
       "18347                  0         0         0      0      ...         \n",
       "1063                   0         0         0      0      ...         \n",
       "12191                  0         0         0      0      ...         \n",
       "10492                  0         0         0      0      ...         \n",
       "821                    0         0         0      0      ...         \n",
       "22400                  0         0         0      0      ...         \n",
       "11315                  0         0         0      0      ...         \n",
       "11514                  0         0         0      0      ...         \n",
       "...                  ...       ...       ...    ...      ...         \n",
       "13501                  0         0         0      0      ...         \n",
       "1432                   0         0         0      0      ...         \n",
       "1307                   0         0         0      0      ...         \n",
       "25179                  0         0         0      0      ...         \n",
       "23584                  0         0         0      0      ...         \n",
       "189                    0         0         0      0      ...         \n",
       "20608                  0         0         0      0      ...         \n",
       "3657                   0         0         0      0      ...         \n",
       "16931                  0         0         0      0      ...         \n",
       "20666                  0         0         0      0      ...         \n",
       "25060                  0         0         0      0      ...         \n",
       "1389                   0         0         0      0      ...         \n",
       "20237                  0         0         0      0      ...         \n",
       "15489                  0         0         0      0      ...         \n",
       "15775                  0         0         0      1      ...         \n",
       "3789                   0         0         0      0      ...         \n",
       "18405                  0         0         1      0      ...         \n",
       "12135                  0         0         0      0      ...         \n",
       "25516                  0         0         0      0      ...         \n",
       "25495                  0         0         0      0      ...         \n",
       "6479                   0         0         0      0      ...         \n",
       "13475                  0         0         0      0      ...         \n",
       "15955                  0         0         0      0      ...         \n",
       "16180                  1         0         0      0      ...         \n",
       "22028                  0         0         0      0      ...         \n",
       "12527                  0         0         1      0      ...         \n",
       "9624                   0         0         0      0      ...         \n",
       "13798                  0         0         0      0      ...         \n",
       "1350                   0         0         0      1      ...         \n",
       "25590                  0         0         0      0      ...         \n",
       "\n",
       "       aid_centers  other_infrastructure  weather_related  floods  storm  \\\n",
       "15196            0                     0                1       1      0   \n",
       "11247            0                     0                1       0      1   \n",
       "844              0                     0                0       0      0   \n",
       "1392             0                     0                0       0      0   \n",
       "25764            0                     0                0       0      0   \n",
       "9090             0                     0                0       0      0   \n",
       "47               0                     0                0       0      0   \n",
       "17534            0                     0                1       1      0   \n",
       "1732             0                     0                0       0      0   \n",
       "12025            0                     0                0       0      0   \n",
       "12249            0                     0                1       1      0   \n",
       "13632            0                     0                1       0      1   \n",
       "11617            0                     0                1       0      0   \n",
       "18124            0                     1                0       0      0   \n",
       "5786             0                     0                0       0      0   \n",
       "7892             0                     0                0       0      0   \n",
       "5598             0                     0                0       0      0   \n",
       "22156            0                     0                0       0      0   \n",
       "11417            0                     0                0       0      0   \n",
       "6615             0                     0                0       0      0   \n",
       "12121            0                     0                0       0      0   \n",
       "2762             0                     0                0       0      0   \n",
       "18347            0                     0                1       0      0   \n",
       "1063             0                     0                0       0      0   \n",
       "12191            0                     0                0       0      0   \n",
       "10492            0                     0                1       0      0   \n",
       "821              0                     0                0       0      0   \n",
       "22400            0                     0                0       0      0   \n",
       "11315            0                     0                0       0      0   \n",
       "11514            0                     0                1       0      0   \n",
       "...            ...                   ...              ...     ...    ...   \n",
       "13501            0                     0                1       0      0   \n",
       "1432             0                     0                0       0      0   \n",
       "1307             0                     0                1       0      0   \n",
       "25179            0                     0                0       0      0   \n",
       "23584            0                     0                0       0      0   \n",
       "189              0                     0                0       0      0   \n",
       "20608            0                     0                0       0      0   \n",
       "3657             0                     0                0       0      0   \n",
       "16931            0                     0                1       0      0   \n",
       "20666            0                     0                0       0      0   \n",
       "25060            0                     0                0       0      0   \n",
       "1389             0                     0                0       0      0   \n",
       "20237            0                     0                0       0      0   \n",
       "15489            0                     0                0       0      0   \n",
       "15775            0                     0                1       0      1   \n",
       "3789             0                     0                0       0      0   \n",
       "18405            0                     0                1       0      1   \n",
       "12135            0                     0                0       0      0   \n",
       "25516            0                     0                0       0      0   \n",
       "25495            0                     0                0       0      0   \n",
       "6479             0                     0                0       0      0   \n",
       "13475            0                     0                1       1      1   \n",
       "15955            0                     0                0       0      0   \n",
       "16180            0                     1                1       1      1   \n",
       "22028            0                     0                1       1      1   \n",
       "12527            0                     0                1       0      1   \n",
       "9624             0                     0                1       0      0   \n",
       "13798            0                     0                1       1      0   \n",
       "1350             0                     0                0       0      0   \n",
       "25590            0                     0                0       0      0   \n",
       "\n",
       "       fire  earthquake  cold  other_weather  direct_report  \n",
       "15196     0           0     0              0              0  \n",
       "11247     0           0     0              0              1  \n",
       "844       0           0     0              0              1  \n",
       "1392      0           0     0              0              0  \n",
       "25764     0           0     0              0              0  \n",
       "9090      0           0     0              0              0  \n",
       "47        0           0     0              0              1  \n",
       "17534     0           0     0              1              0  \n",
       "1732      0           0     0              0              0  \n",
       "12025     0           0     0              0              0  \n",
       "12249     0           0     0              0              1  \n",
       "13632     0           0     0              0              0  \n",
       "11617     0           1     0              0              1  \n",
       "18124     0           0     0              0              0  \n",
       "5786      0           0     0              0              0  \n",
       "7892      0           0     0              0              0  \n",
       "5598      0           0     0              0              0  \n",
       "22156     0           0     0              0              0  \n",
       "11417     0           0     0              0              0  \n",
       "6615      0           0     0              0              0  \n",
       "12121     0           0     0              0              0  \n",
       "2762      0           0     0              0              1  \n",
       "18347     0           0     0              1              1  \n",
       "1063      0           0     0              0              1  \n",
       "12191     0           0     0              0              1  \n",
       "10492     0           1     0              0              0  \n",
       "821       0           0     0              0              1  \n",
       "22400     0           0     0              0              0  \n",
       "11315     0           0     0              0              0  \n",
       "11514     1           0     0              0              1  \n",
       "...     ...         ...   ...            ...            ...  \n",
       "13501     0           1     0              0              0  \n",
       "1432      0           0     0              0              0  \n",
       "1307      0           1     0              0              1  \n",
       "25179     0           0     0              0              0  \n",
       "23584     0           0     0              0              0  \n",
       "189       0           0     0              0              1  \n",
       "20608     0           0     0              0              1  \n",
       "3657      0           0     0              0              0  \n",
       "16931     0           0     0              1              0  \n",
       "20666     0           0     0              0              0  \n",
       "25060     0           0     0              0              0  \n",
       "1389      0           0     0              0              0  \n",
       "20237     0           0     0              0              0  \n",
       "15489     0           0     0              0              0  \n",
       "15775     0           1     0              0              0  \n",
       "3789      0           0     0              0              0  \n",
       "18405     0           0     1              0              0  \n",
       "12135     0           0     0              0              0  \n",
       "25516     0           0     0              0              0  \n",
       "25495     0           0     0              0              0  \n",
       "6479      0           0     0              0              0  \n",
       "13475     0           0     0              0              0  \n",
       "15955     0           0     0              0              0  \n",
       "16180     0           0     0              0              0  \n",
       "22028     0           0     0              0              0  \n",
       "12527     0           0     0              0              0  \n",
       "9624      0           1     0              0              0  \n",
       "13798     0           0     0              1              0  \n",
       "1350      0           0     0              0              0  \n",
       "25590     0           0     0              0              0  \n",
       "\n",
       "[19662 rows x 35 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test three different classifiers before tuning hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0068660360085444003"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train.related==2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the related = 2 labels - this will allow me to use hamming loss\n",
    "y_train.loc[y_train.related == 2, 'related'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune the grid with hamming loss instead - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hamming_loss.html\n",
    "# make a custom scorer https://scikit-learn.org/stable/modules/model_evaluation.html#scoring\n",
    "from sklearn.metrics import hamming_loss, make_scorer\n",
    "hamming_scorer = make_scorer(hamming_loss, greater_is_better=False)\n",
    "\n",
    "# search over a grid of possible classifiers to determine which might be the best fit for our data\n",
    "# using hamming loss as the score metric. This gives the proportion of labels which are correct in a multilabel output.\n",
    "\n",
    "#clf_params = {\n",
    "#    'clf__estimator': [RandomForestClassifier(), SVC(kernel='linear'), GaussianNB()]  \n",
    "#}\n",
    "\n",
    "#clf_cv = GridSearchCV(pipeline, clf_params, scoring=hamming_scorer)\n",
    "#clf_search = clf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_compare(y_pred, y_train):\n",
    "    y_pred2 = pd.DataFrame(y_pred, columns=Y.columns)\n",
    "    y_train2 = pd.DataFrame(y_train, columns=Y.columns)\n",
    "\n",
    "    for col in Y.columns:\n",
    "        print(col, '\\n', classification_report(y_pred2[col], y_train2[col]))\n",
    "        \n",
    "    print(f\"Hamming Loss: {hamming_loss(y_pred, y_train)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.98      0.98      4627\n",
      "        1.0       0.99      0.99      0.99     15035\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "request \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.98      0.99     16572\n",
      "        1.0       0.92      1.00      0.96      3090\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "offer \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     19594\n",
      "        1.0       0.73      1.00      0.84        68\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "aid_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.97      0.98     11810\n",
      "        1.0       0.96      1.00      0.98      7852\n",
      "\n",
      "avg / total       0.98      0.98      0.98     19662\n",
      "\n",
      "medical_help \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.98      0.99     18376\n",
      "        1.0       0.81      1.00      0.89      1286\n",
      "\n",
      "avg / total       0.99      0.98      0.99     19662\n",
      "\n",
      "medical_products \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      0.99     18891\n",
      "        1.0       0.77      1.00      0.87       771\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "search_and_rescue \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00     19215\n",
      "        1.0       0.80      1.00      0.89       447\n",
      "\n",
      "avg / total       1.00      0.99      0.99     19662\n",
      "\n",
      "security \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     19381\n",
      "        1.0       0.80      1.00      0.89       281\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "military \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00     19104\n",
      "        1.0       0.84      0.99      0.91       558\n",
      "\n",
      "avg / total       1.00      0.99      0.99     19662\n",
      "\n",
      "water \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00     18512\n",
      "        1.0       0.91      1.00      0.95      1150\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "food \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00     17588\n",
      "        1.0       0.94      1.00      0.97      2074\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "shelter \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00     18095\n",
      "        1.0       0.90      1.00      0.95      1567\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "clothing \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     19406\n",
      "        1.0       0.82      1.00      0.90       256\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "money \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     19311\n",
      "        1.0       0.79      1.00      0.89       351\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "missing_people \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     19503\n",
      "        1.0       0.75      1.00      0.86       159\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "refugees \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00     19125\n",
      "        1.0       0.80      1.00      0.89       537\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "death \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00     18875\n",
      "        1.0       0.87      1.00      0.93       787\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "other_aid \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.98      0.99     17462\n",
      "        1.0       0.84      1.00      0.91      2200\n",
      "\n",
      "avg / total       0.98      0.98      0.98     19662\n",
      "\n",
      "infrastructure_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.98      0.99     18666\n",
      "        1.0       0.78      1.00      0.88       996\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "transport \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00     18929\n",
      "        1.0       0.80      1.00      0.89       733\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "buildings \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00     18847\n",
      "        1.0       0.82      1.00      0.90       815\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "electricity \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     19340\n",
      "        1.0       0.79      1.00      0.88       322\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "tools \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     19574\n",
      "        1.0       0.70      1.00      0.83        88\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "hospitals \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     19503\n",
      "        1.0       0.73      1.00      0.84       159\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "shops \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     19602\n",
      "        1.0       0.70      1.00      0.82        60\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "aid_centers \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     19496\n",
      "        1.0       0.72      1.00      0.84       166\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "other_infrastructure \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      0.99     18996\n",
      "        1.0       0.77      1.00      0.87       666\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "weather_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.98      0.99     14482\n",
      "        1.0       0.95      1.00      0.97      5180\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "floods \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00     18217\n",
      "        1.0       0.90      1.00      0.95      1445\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "storm \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00     17985\n",
      "        1.0       0.92      1.00      0.96      1677\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "fire \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     19485\n",
      "        1.0       0.80      1.00      0.89       177\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "earthquake \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00     17958\n",
      "        1.0       0.94      1.00      0.97      1704\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "cold \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     19342\n",
      "        1.0       0.80      1.00      0.89       320\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "other_weather \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      0.99     18819\n",
      "        1.0       0.79      1.00      0.88       843\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "direct_report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.98      0.99     16226\n",
      "        1.0       0.90      1.00      0.95      3436\n",
      "\n",
      "avg / total       0.98      0.98      0.98     19662\n",
      "\n",
      "Hamming Loss: 0.008014008166586744\n"
     ]
    }
   ],
   "source": [
    "# RF supports direct multi label output - don't have to wrap in a MultiOutputClassifier\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('msg_tokenizer', MessageTokenizer()),\n",
    "    # Count Vectorizer with Tokenizer\n",
    "    ('count_vec', CountVectorizer(tokenizer=tokenize)),\n",
    "    # TF-IDF Transformer\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # classifier - one classifier per label\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "y_pred_rf = pipeline_rf.predict(X_train)\n",
    "\n",
    "model_compare(y_pred_rf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8% of labels are predicted incorrectly with RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.88      0.79      3809\n",
      "          1       0.97      0.92      0.94     15853\n",
      "\n",
      "avg / total       0.92      0.91      0.91     19662\n",
      "\n",
      "request \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.94      0.96     17116\n",
      "          1       0.68      0.90      0.77      2546\n",
      "\n",
      "avg / total       0.94      0.93      0.94     19662\n",
      "\n",
      "offer \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19662\n",
      "          1       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "aid_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.88      0.90     12066\n",
      "          1       0.82      0.88      0.85      7596\n",
      "\n",
      "avg / total       0.88      0.88      0.88     19662\n",
      "\n",
      "medical_help \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97     18958\n",
      "          1       0.40      0.89      0.55       704\n",
      "\n",
      "avg / total       0.97      0.95      0.96     19662\n",
      "\n",
      "medical_products \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98     19255\n",
      "          1       0.36      0.89      0.52       407\n",
      "\n",
      "avg / total       0.98      0.97      0.97     19662\n",
      "\n",
      "search_and_rescue \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     19510\n",
      "          1       0.25      0.92      0.40       152\n",
      "\n",
      "avg / total       0.99      0.98      0.98     19662\n",
      "\n",
      "security \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     19658\n",
      "          1       0.01      1.00      0.02         4\n",
      "\n",
      "avg / total       1.00      0.98      0.99     19662\n",
      "\n",
      "military \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99     19262\n",
      "          1       0.58      0.94      0.72       400\n",
      "\n",
      "avg / total       0.99      0.98      0.99     19662\n",
      "\n",
      "water \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99     18517\n",
      "          1       0.82      0.91      0.86      1145\n",
      "\n",
      "avg / total       0.98      0.98      0.98     19662\n",
      "\n",
      "food \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.98     17615\n",
      "          1       0.82      0.88      0.85      2047\n",
      "\n",
      "avg / total       0.97      0.97      0.97     19662\n",
      "\n",
      "shelter \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.97      0.98     18366\n",
      "          1       0.67      0.90      0.76      1296\n",
      "\n",
      "avg / total       0.97      0.96      0.97     19662\n",
      "\n",
      "clothing \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     19438\n",
      "          1       0.64      0.89      0.74       224\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "money \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99     19501\n",
      "          1       0.35      0.96      0.51       161\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "missing_people \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     19639\n",
      "          1       0.10      0.96      0.19        23\n",
      "\n",
      "avg / total       1.00      0.99      0.99     19662\n",
      "\n",
      "refugees \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     19415\n",
      "          1       0.35      0.94      0.50       247\n",
      "\n",
      "avg / total       0.99      0.98      0.98     19662\n",
      "\n",
      "death \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     19029\n",
      "          1       0.65      0.93      0.77       633\n",
      "\n",
      "avg / total       0.99      0.98      0.98     19662\n",
      "\n",
      "other_aid \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94     19099\n",
      "          1       0.20      0.92      0.33       563\n",
      "\n",
      "avg / total       0.97      0.89      0.92     19662\n",
      "\n",
      "infrastructure_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97     19638\n",
      "          1       0.02      0.96      0.04        24\n",
      "\n",
      "avg / total       1.00      0.94      0.97     19662\n",
      "\n",
      "transport \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98     19385\n",
      "          1       0.29      0.95      0.44       277\n",
      "\n",
      "avg / total       0.99      0.97      0.98     19662\n",
      "\n",
      "buildings \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99     19121\n",
      "          1       0.51      0.94      0.66       541\n",
      "\n",
      "avg / total       0.98      0.97      0.98     19662\n",
      "\n",
      "electricity \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99     19439\n",
      "          1       0.52      0.95      0.67       223\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n",
      "tools \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     19662\n",
      "          1       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.99      1.00     19662\n",
      "\n",
      "hospitals \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99     19656\n",
      "          1       0.03      1.00      0.05         6\n",
      "\n",
      "avg / total       1.00      0.99      0.99     19662\n",
      "\n",
      "shops \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19662\n",
      "          1       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19662\n",
      "\n",
      "aid_centers \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99     19662\n",
      "          1       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.99      0.99     19662\n",
      "\n",
      "other_infrastructure \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98     19659\n",
      "          1       0.00      1.00      0.01         3\n",
      "\n",
      "avg / total       1.00      0.96      0.98     19662\n",
      "\n",
      "weather_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.93      0.95     14869\n",
      "          1       0.82      0.92      0.87      4793\n",
      "\n",
      "avg / total       0.94      0.93      0.93     19662\n",
      "\n",
      "floods \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98     18658\n",
      "          1       0.59      0.94      0.72      1004\n",
      "\n",
      "avg / total       0.98      0.96      0.97     19662\n",
      "\n",
      "storm \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.98     18100\n",
      "          1       0.76      0.89      0.82      1562\n",
      "\n",
      "avg / total       0.97      0.97      0.97     19662\n",
      "\n",
      "fire \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     19564\n",
      "          1       0.43      0.97      0.60        98\n",
      "\n",
      "avg / total       1.00      0.99      0.99     19662\n",
      "\n",
      "earthquake \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.99     18042\n",
      "          1       0.83      0.93      0.88      1620\n",
      "\n",
      "avg / total       0.98      0.98      0.98     19662\n",
      "\n",
      "cold \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99     19444\n",
      "          1       0.52      0.94      0.67       218\n",
      "\n",
      "avg / total       0.99      0.99      0.99     19662\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other_weather \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98     19418\n",
      "          1       0.21      0.92      0.34       244\n",
      "\n",
      "avg / total       0.99      0.96      0.97     19662\n",
      "\n",
      "direct_report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.91      0.94     17063\n",
      "          1       0.60      0.87      0.71      2599\n",
      "\n",
      "avg / total       0.93      0.91      0.91     19662\n",
      "\n",
      "Hamming Loss: 0.034697821759158344\n"
     ]
    }
   ],
   "source": [
    "pipeline_svc = Pipeline([\n",
    "    ('msg_tokenizer', MessageTokenizer()),\n",
    "    # Count Vectorizer with Tokenizer\n",
    "    ('count_vec', CountVectorizer(tokenizer=tokenize)),\n",
    "    # TF-IDF Transformer\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # classifier - one classifier per label\n",
    "    ('clf', MultiOutputClassifier(estimator=SVC(kernel='linear')))\n",
    "])\n",
    "\n",
    "pipeline_svc.fit(X_train, y_train)\n",
    "y_pred_svc = pipeline_svc.predict(X_train)\n",
    "\n",
    "model_compare(y_pred_svc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVC Classifier is not as good at distinguishing between the majority and the minority classes. Accuracy on the individual labels is worse, and Hamming score is worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DenseTranformer class to make sure the output is correct for the GaussianNB\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_nb = Pipeline([\n",
    "    ('msg_tokenizer', MessageTokenizer()),\n",
    "    # Count Vectorizer with Tokenizer\n",
    "    ('count_vec', CountVectorizer(tokenizer=tokenize)),\n",
    "    # TF-IDF Transformer\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # make sure the output is dense, not sparse - needed for GaussianNB\n",
    "    ('dense', DenseTransformer()),\n",
    "    # classifier - one classifier per label\n",
    "    ('clf', MultiOutputClassifier(estimator=GaussianNB()))\n",
    "])\n",
    "\n",
    "pipeline_nb.fit(X_train.values, y_train)\n",
    "y_pred_nb = pipeline_nb.predict(X_train.values)\n",
    "\n",
    "model_compare(y_pred_nb, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing to go with the RandomForest model because it seems to yield the best results on training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomizedSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ae2fec35b5c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhamming_scorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomizedSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "search_params = {\n",
    "    'msg_tokenizer__remove_stops': [False, True],\n",
    "    'msg_tokenizer__lemmatize': [False, True],\n",
    "    'count_vec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'count_vec__max_features': [None, 100, 500, 1000],\n",
    "    'tfidf__norm': [None, 'l1', 'l2'],\n",
    "    'tfidf__use_idf': [False, True],\n",
    "    'tfidf__smooth_idf': [False, True],\n",
    "    'clf__estimator__n_estimators': [10, 100, 500],\n",
    "    'clf__estimator__max_depth': [None, 50, 100, 500],\n",
    "    'clf__estimator__bootstrap': [True, False],\n",
    "    'clf__estimator__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "cv = RandomizedSearchCV(pipeline, search_params, n_iter=5, n_jobs=-1, scoring=hamming_scorer)\n",
    "search = cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = RandomizedSearchCV(pipeline, search_params, n_iter=10, n_jobs=-1, scoring=hamming_score)\n",
    "search2 = cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
