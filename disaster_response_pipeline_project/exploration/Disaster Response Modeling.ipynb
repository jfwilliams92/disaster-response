{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaster Reponse Pipeline Creation \n",
    "\n",
    "We are faced with a difficult problem. We have a relatively smalle dataset of 26k messages received during a time of natural disaster. \n",
    "Our task is to distinguish signal from noise - in this case the signal is those people who need aid of some kind. The messages originating from those in need may be hard to detect in the tide of messages related to the disaster.\n",
    "<p>\n",
    "With luck we can train a classifier or series of classifiers to inform us of signal in noise by applying one or more labels to relevant messages.\n",
    "\n",
    "\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jwilliams1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jwilliams1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jwilliams1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jwilliams1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import hamming_loss, make_scorer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterMessages.db')\n",
    "df = pd.read_sql('SELECT * FROM CleanMessages', engine)\n",
    "\n",
    "# define variables. X is input, Y is target\n",
    "X = df['message']\n",
    "Y = df.drop(['id', 'message', 'original', 'genre'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure we have at least one instance for each label\n",
    "labels_with_no_instance = Y.columns[~(Y == 1).any(axis=0)]\n",
    "Y = Y.drop(labels_with_no_instance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['child_alone'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_with_no_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "related                   False\n",
       "request                    True\n",
       "offer                      True\n",
       "aid_related                True\n",
       "medical_help               True\n",
       "medical_products           True\n",
       "search_and_rescue          True\n",
       "security                   True\n",
       "military                   True\n",
       "water                      True\n",
       "food                       True\n",
       "shelter                    True\n",
       "clothing                   True\n",
       "money                      True\n",
       "missing_people             True\n",
       "refugees                   True\n",
       "death                      True\n",
       "other_aid                  True\n",
       "infrastructure_related     True\n",
       "transport                  True\n",
       "buildings                  True\n",
       "electricity                True\n",
       "tools                      True\n",
       "hospitals                  True\n",
       "shops                      True\n",
       "aid_centers                True\n",
       "other_infrastructure       True\n",
       "weather_related            True\n",
       "floods                     True\n",
       "storm                      True\n",
       "fire                       True\n",
       "earthquake                 True\n",
       "cold                       True\n",
       "other_weather              True\n",
       "direct_report              True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for labels that are not binary\n",
    "(Y.isin([0, 1])).all(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh! Looks like all of our labels are binary except for the 'related' column.\n",
    "Let's check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    19906\n",
      "0     6122\n",
      "2      188\n",
      "Name: related, dtype: int64\n",
      "1    0.759307\n",
      "0    0.233522\n",
      "2    0.007171\n",
      "Name: related, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cnts = Y.related.value_counts()\n",
    "print(cnts)\n",
    "print(cnts / cnts.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have 188 instances of 'related' not binary, which is 0.7% of the instances in the dataset.\n",
    "Looks like the non binary values of related are 2's. \n",
    "Since the number is so small, we'll drop them from the dataset. The reasoning behind this approach is that by dropping these rows, we transform the problem from a multiclass-multilabel problem, known as a multioutput problem, down to a multilabel problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = Y[Y.related == 2].index\n",
    "Y = Y.drop(index)\n",
    "X = X.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26028,), (26028, 35))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products      ...        \\\n",
       "0        0      0            0             0                 0      ...         \n",
       "1        0      0            1             0                 0      ...         \n",
       "2        0      0            0             0                 0      ...         \n",
       "3        1      0            1             0                 1      ...         \n",
       "4        0      0            0             0                 0      ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "4            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "4           0     0              0              0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26216, 40)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of the original data \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've dropped 188 rows and 5 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization class to process the text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization is a way to reduce words to their root or base form. <br>\n",
    "The process is more accurate if the lemmatizer knows to which part of speech the word belongs. <br>\n",
    "Therefore, as part of the lemmatization process, we will tag each word with nltk's pos_tag function. <br>\n",
    "This POS tag is a Treebank POS tag - in order to utilize it with the WordNet lemmatizer, we have to convert the Treebank POS tag to a WordNet POS tag. <br>\n",
    "Then, we will pass this POS tag to the lemmatizer along with the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that will allow a treebank POS tag to be converted into a WordNet\n",
    "# POS Tag so the lemmatizer will understand it\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    # default to Noun \n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing stop words is another common step in processing text data. Stop words are common words in a language that may potentially confuse a classifier due to their frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement a custom transformer with hyperparameters in order to determine if removing stop words and/or lemmatizing words will have a positive effect on classification efficacy.\n",
    "This custom transformer follows sklearn's rules for transformers so that it can be used in our processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a custom transformer to determine if removing stops and/or lemmatizing improves model performance\n",
    "\n",
    "class MessageTokenizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, remove_stops=True, lemmatize=True):\n",
    "        self.remove_stops = remove_stops\n",
    "        self.lemmatize = lemmatize\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        \n",
    "        # iterate over supplied messages\n",
    "        for text in X: \n",
    "            # sub out any urls \n",
    "            text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "            \n",
    "            # remove all non-alphanumeric characters\n",
    "            text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "              \n",
    "            # lower and strip whitespace\n",
    "            text = text.lower().strip()\n",
    "    \n",
    "            # tokenize words - nltk.tokenize.word_tokenize\n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.lemmatize:\n",
    "                # tag words with Part of Speech - list of (word, POS) tuples \n",
    "                # nltk.pos_tag()\n",
    "                words_with_pos_tag = pos_tag(words)\n",
    "                \n",
    "                if self.remove_stops:\n",
    "                    # remove stop words\n",
    "                    # stop_words = nlt.corpus.stopwords of 'english' language\n",
    "                    words_with_pos_tag = [word for word in words_with_pos_tag if word[0] not in stop_words]\n",
    "                \n",
    "                # change pos tags to wordnet pos tags for lemmatizer\n",
    "                words_with_wordnet_tag = []\n",
    "    \n",
    "                for word_with_tag in words_with_pos_tag:\n",
    "                    word, tag = word_with_tag\n",
    "                    tag = get_wordnet_pos(tag)\n",
    "                    words_with_wordnet_tag.append((word, tag))\n",
    "\n",
    "                # lemmatize\n",
    "                lemm = WordNetLemmatizer()\n",
    "                # unpack the (word, pos) tuple into the Lemmatizer to give better lemmatization \n",
    "                # lemmatization is more effective when it knows the correct part of speech\n",
    "                words = [lemm.lemmatize(*w) for w in words_with_wordnet_tag]\n",
    "                \n",
    "            else:\n",
    "                if self.remove_stops:\n",
    "                    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "            # join cleaned words back into single document\n",
    "            X_transformed.append(' '.join(words))\n",
    "        \n",
    "        return X_transformed    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show off the custom transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We would not want these words taking up space in our database, or taking up valuable processing time. For this, we can remove them easily, by storing a list of words that you consider to be stop words',\n",
       " \"Here is another example of words. Isn't it great how words can be manipulated?\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"We would not want these words taking up space in our database, or taking up valuable processing time. For this, we can remove them easily, by storing a list of words that you consider to be stop words\"]\n",
    "text.append(\"Here is another example of words. Isn't it great how words can be manipulated?\")\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we would not want these word take up space in our database or take up valuable processing time for this we can remove them easily by store a list of word that you consider to be stop word',\n",
       " 'here be another example of word isn t it great how word can be manipulate']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MessageTokenizer(remove_stops=False, lemmatize=True).transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a first machine learning pipeline\n",
    "A pipeline allows us to wrap all of our data transformation steps into a neat little package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('msg_tokenizer', MessageTokenizer()),\n",
    "    # Count Vectorizer with Tokenizer\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    # TF-IDF Transformer\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # classifier - one classifier per label\n",
    "    ('clf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a multilabel classification, I looked into the iterative train-test-split supplied by skmultilearn.\n",
    "The idea with the iterative train test split is that in theory it can provide better label representation for mutli label problems. Here I will compare whether this train test split results in appropriate label representation for the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the proportion of labels in the original data\n",
    "compare = pd.DataFrame(Y.mean(axis=0), columns=['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.764792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.171892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.004534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.417243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.080068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset\n",
       "related       0.764792\n",
       "request       0.171892\n",
       "offer         0.004534\n",
       "aid_related   0.417243\n",
       "medical_help  0.080068"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employ skmultilearn's iterative train test split.\n",
    "# have to reshape the X values to be multidimensional since that's what this expects\n",
    "\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X.values.reshape(-1,1), Y.values, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to see how the iterative split did with label proportions\n",
    "compare['train_set'] = y_train.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal train test split - how does it compare\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare['normal_split'] = y_train2.values.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train_set</th>\n",
       "      <th>normal_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.764792</td>\n",
       "      <td>0.764766</td>\n",
       "      <td>0.763793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.171892</td>\n",
       "      <td>0.136929</td>\n",
       "      <td>0.172174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.004534</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.004713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.417243</td>\n",
       "      <td>0.417243</td>\n",
       "      <td>0.416218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.080068</td>\n",
       "      <td>0.087496</td>\n",
       "      <td>0.080068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.050446</td>\n",
       "      <td>0.052764</td>\n",
       "      <td>0.051022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.027816</td>\n",
       "      <td>0.028277</td>\n",
       "      <td>0.027765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.018096</td>\n",
       "      <td>0.019415</td>\n",
       "      <td>0.018493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.033041</td>\n",
       "      <td>0.041596</td>\n",
       "      <td>0.032119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.064239</td>\n",
       "      <td>0.063521</td>\n",
       "      <td>0.064187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.112302</td>\n",
       "      <td>0.100968</td>\n",
       "      <td>0.112648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.088904</td>\n",
       "      <td>0.086471</td>\n",
       "      <td>0.087854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.015560</td>\n",
       "      <td>0.013114</td>\n",
       "      <td>0.015727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.023206</td>\n",
       "      <td>0.024230</td>\n",
       "      <td>0.023667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.011449</td>\n",
       "      <td>0.011116</td>\n",
       "      <td>0.011372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.033618</td>\n",
       "      <td>0.038113</td>\n",
       "      <td>0.034220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.045874</td>\n",
       "      <td>0.049434</td>\n",
       "      <td>0.045848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.132396</td>\n",
       "      <td>0.122125</td>\n",
       "      <td>0.132780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.065506</td>\n",
       "      <td>0.068285</td>\n",
       "      <td>0.066083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.046143</td>\n",
       "      <td>0.046975</td>\n",
       "      <td>0.046412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.051214</td>\n",
       "      <td>0.051227</td>\n",
       "      <td>0.051227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.020440</td>\n",
       "      <td>0.020440</td>\n",
       "      <td>0.020388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.006109</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.005942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.010873</td>\n",
       "      <td>0.011577</td>\n",
       "      <td>0.010860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.004610</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.004764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.011872</td>\n",
       "      <td>0.012755</td>\n",
       "      <td>0.011885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.044222</td>\n",
       "      <td>0.046155</td>\n",
       "      <td>0.045080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.280352</td>\n",
       "      <td>0.280365</td>\n",
       "      <td>0.284104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.082795</td>\n",
       "      <td>0.092874</td>\n",
       "      <td>0.083449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.093860</td>\n",
       "      <td>0.093284</td>\n",
       "      <td>0.095999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.010834</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>0.011116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.094321</td>\n",
       "      <td>0.082424</td>\n",
       "      <td>0.095231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.020363</td>\n",
       "      <td>0.022028</td>\n",
       "      <td>0.020644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.052866</td>\n",
       "      <td>0.058911</td>\n",
       "      <td>0.053891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.194982</td>\n",
       "      <td>0.159264</td>\n",
       "      <td>0.194970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         dataset  train_set  normal_split\n",
       "related                 0.764792   0.764766      0.763793\n",
       "request                 0.171892   0.136929      0.172174\n",
       "offer                   0.004534   0.004559      0.004713\n",
       "aid_related             0.417243   0.417243      0.416218\n",
       "medical_help            0.080068   0.087496      0.080068\n",
       "medical_products        0.050446   0.052764      0.051022\n",
       "search_and_rescue       0.027816   0.028277      0.027765\n",
       "security                0.018096   0.019415      0.018493\n",
       "military                0.033041   0.041596      0.032119\n",
       "water                   0.064239   0.063521      0.064187\n",
       "food                    0.112302   0.100968      0.112648\n",
       "shelter                 0.088904   0.086471      0.087854\n",
       "clothing                0.015560   0.013114      0.015727\n",
       "money                   0.023206   0.024230      0.023667\n",
       "missing_people          0.011449   0.011116      0.011372\n",
       "refugees                0.033618   0.038113      0.034220\n",
       "death                   0.045874   0.049434      0.045848\n",
       "other_aid               0.132396   0.122125      0.132780\n",
       "infrastructure_related  0.065506   0.068285      0.066083\n",
       "transport               0.046143   0.046975      0.046412\n",
       "buildings               0.051214   0.051227      0.051227\n",
       "electricity             0.020440   0.020440      0.020388\n",
       "tools                   0.006109   0.006557      0.005942\n",
       "hospitals               0.010873   0.011577      0.010860\n",
       "shops                   0.004610   0.004662      0.004764\n",
       "aid_centers             0.011872   0.012755      0.011885\n",
       "other_infrastructure    0.044222   0.046155      0.045080\n",
       "weather_related         0.280352   0.280365      0.284104\n",
       "floods                  0.082795   0.092874      0.083449\n",
       "storm                   0.093860   0.093284      0.095999\n",
       "fire                    0.010834   0.011833      0.011116\n",
       "earthquake              0.094321   0.082424      0.095231\n",
       "cold                    0.020363   0.022028      0.020644\n",
       "other_weather           0.052866   0.058911      0.053891\n",
       "direct_report           0.194982   0.159264      0.194970"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset - normalsplit</th>\n",
       "      <th>dataset - iterative split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>-0.000282</td>\n",
       "      <td>0.034962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>-0.000179</td>\n",
       "      <td>-0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>-0.000576</td>\n",
       "      <td>-0.002318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.000051</td>\n",
       "      <td>-0.000461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>-0.000397</td>\n",
       "      <td>-0.001319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.000922</td>\n",
       "      <td>-0.008555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>-0.000346</td>\n",
       "      <td>0.011334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.002433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>-0.000166</td>\n",
       "      <td>0.002446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.001025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>-0.000602</td>\n",
       "      <td>-0.004495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.003560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>-0.000384</td>\n",
       "      <td>0.010271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>-0.000576</td>\n",
       "      <td>-0.002779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>-0.000269</td>\n",
       "      <td>-0.000832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.000166</td>\n",
       "      <td>-0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>-0.000154</td>\n",
       "      <td>-0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>-0.000858</td>\n",
       "      <td>-0.001934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>-0.003752</td>\n",
       "      <td>-0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>-0.000653</td>\n",
       "      <td>-0.010079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>-0.002139</td>\n",
       "      <td>0.000576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>-0.000282</td>\n",
       "      <td>-0.000999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>-0.000909</td>\n",
       "      <td>0.011897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>-0.000282</td>\n",
       "      <td>-0.001665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>-0.001025</td>\n",
       "      <td>-0.006045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.035718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        dataset - normalsplit  dataset - iterative split\n",
       "related                              0.000999                   0.000026\n",
       "request                             -0.000282                   0.034962\n",
       "offer                               -0.000179                  -0.000026\n",
       "aid_related                          0.001025                   0.000000\n",
       "medical_help                         0.000000                  -0.007428\n",
       "medical_products                    -0.000576                  -0.002318\n",
       "search_and_rescue                    0.000051                  -0.000461\n",
       "security                            -0.000397                  -0.001319\n",
       "military                             0.000922                  -0.008555\n",
       "water                                0.000051                   0.000717\n",
       "food                                -0.000346                   0.011334\n",
       "shelter                              0.001050                   0.002433\n",
       "clothing                            -0.000166                   0.002446\n",
       "money                               -0.000461                  -0.001025\n",
       "missing_people                       0.000077                   0.000333\n",
       "refugees                            -0.000602                  -0.004495\n",
       "death                                0.000026                  -0.003560\n",
       "other_aid                           -0.000384                   0.010271\n",
       "infrastructure_related              -0.000576                  -0.002779\n",
       "transport                           -0.000269                  -0.000832\n",
       "buildings                           -0.000013                  -0.000013\n",
       "electricity                          0.000051                   0.000000\n",
       "tools                                0.000166                  -0.000448\n",
       "hospitals                            0.000013                  -0.000704\n",
       "shops                               -0.000154                  -0.000051\n",
       "aid_centers                         -0.000013                  -0.000884\n",
       "other_infrastructure                -0.000858                  -0.001934\n",
       "weather_related                     -0.003752                  -0.000013\n",
       "floods                              -0.000653                  -0.010079\n",
       "storm                               -0.002139                   0.000576\n",
       "fire                                -0.000282                  -0.000999\n",
       "earthquake                          -0.000909                   0.011897\n",
       "cold                                -0.000282                  -0.001665\n",
       "other_weather                       -0.001025                  -0.006045\n",
       "direct_report                        0.000013                   0.035718"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = pd.DataFrame(compare['dataset'] - compare['normal_split'])\n",
    "diff.columns = ['dataset - normalsplit']\n",
    "diff['dataset - iterative split'] = compare['dataset'] - compare['train_set']\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "diff.plot(kind='barh', ax=ax)\n",
    "plt.xlabel('Diff in label proportion from original')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the normal train-test-split does a fine, if not better job, of capturing nearly the same proportion of labels as in the original dataset. <br>\n",
    "Since we will be using a OneVsRest strategy, we are interested in keeping the split proportion close to that of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train into train and validation set - we'll hold the test set out for the very end.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('msg_tokenizer', MessageTokenizer(lemmatize=True, remove_stops=True)), ('count_vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the pipeline!\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the fitted model on the train data and the validation data.\n",
    "We'll save the test data for the very end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_pred_val = pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_train = pipeline.predict_proba(X_train)\n",
    "y_prob_val = pipeline.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16657, 35), (4165, 35), (5206, 35))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train.shape, y_pred_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example output:\n",
      "\n",
      "related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      3920\n",
      "         1.0       0.99      0.99      0.99     12737\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     16657\n",
      "   macro avg       0.99      0.99      0.99     16657\n",
      "weighted avg       0.99      0.99      0.99     16657\n",
      "\n",
      "[[ 3856    64]\n",
      " [   68 12669]]\n",
      "request \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99     13952\n",
      "         1.0       0.93      1.00      0.96      2705\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     16657\n",
      "   macro avg       0.97      0.99      0.98     16657\n",
      "weighted avg       0.99      0.99      0.99     16657\n",
      "\n",
      "[[13755   197]\n",
      " [   11  2694]]\n",
      "\n",
      "....... lots more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iterate thru all the labels and check the precision, recall, and f1 score on each individual label for the training data \n",
    "\n",
    "\"\"\"\n",
    "y_pred_train = pd.DataFrame(y_pred_train, columns=Y.columns)\n",
    "y_train = pd.DataFrame(y_train, columns=Y.columns)\n",
    "\n",
    "for col in Y.columns:\n",
    "    print(col, '\\n', classification_report(y_train[col], y_pred_train[col]))\n",
    "    print(confusion_matrix(y_train[col], y_pred_train[col]))\n",
    "\"\"\"\n",
    "\n",
    "print(\"\"\"\n",
    "Example output:\n",
    "\n",
    "related \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.98      0.98      0.98      3920\n",
    "         1.0       0.99      0.99      0.99     12737\n",
    "\n",
    "   micro avg       0.99      0.99      0.99     16657\n",
    "   macro avg       0.99      0.99      0.99     16657\n",
    "weighted avg       0.99      0.99      0.99     16657\n",
    "\n",
    "[[ 3856    64]\n",
    " [   68 12669]]\n",
    "request \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99     13952\n",
    "         1.0       0.93      1.00      0.96      2705\n",
    "\n",
    "   micro avg       0.99      0.99      0.99     16657\n",
    "   macro avg       0.97      0.99      0.98     16657\n",
    "weighted avg       0.99      0.99      0.99     16657\n",
    "\n",
    "[[13755   197]\n",
    " [   11  2694]]\n",
    "\n",
    "....... lots more\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example output:\n",
      "\n",
      "related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.64      0.58       827\n",
      "         1.0       0.91      0.86      0.88      3338\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      4165\n",
      "   macro avg       0.71      0.75      0.73      4165\n",
      "weighted avg       0.83      0.81      0.82      4165\n",
      "\n",
      "related \n",
      " [[ 528  299]\n",
      " [ 481 2857]]\n",
      "\n",
      "\n",
      "request \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.90      0.94      3804\n",
      "         1.0       0.43      0.81      0.56       361\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      4165\n",
      "   macro avg       0.71      0.85      0.75      4165\n",
      "weighted avg       0.93      0.89      0.90      4165\n",
      "\n",
      "request \n",
      " [[3415  389]\n",
      " [  68  293]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# looks good on the training data - how does it do on validation data?\n",
    "\"\"\"\n",
    "y_pred_val = pd.DataFrame(y_pred_val, columns=Y.columns)\n",
    "y_val = pd.DataFrame(y_val, columns=Y.columns)\n",
    "\n",
    "for col in Y.columns:\n",
    "    print(col, '\\n', classification_report(y_val[col], y_pred_val[col]))\n",
    "    print(col, '\\n', confusion_matrix(y_val[col], y_pred_val[col]))\n",
    "    print('\\n')\n",
    "\"\"\"\n",
    "print(\"\"\"\n",
    "Example output:\n",
    "\n",
    "related \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.52      0.64      0.58       827\n",
    "         1.0       0.91      0.86      0.88      3338\n",
    "\n",
    "   micro avg       0.81      0.81      0.81      4165\n",
    "   macro avg       0.71      0.75      0.73      4165\n",
    "weighted avg       0.83      0.81      0.82      4165\n",
    "\n",
    "related \n",
    " [[ 528  299]\n",
    " [ 481 2857]]\n",
    "\n",
    "\n",
    "request \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.98      0.90      0.94      3804\n",
    "         1.0       0.43      0.81      0.56       361\n",
    "\n",
    "   micro avg       0.89      0.89      0.89      4165\n",
    "   macro avg       0.71      0.85      0.75      4165\n",
    "weighted avg       0.93      0.89      0.90      4165\n",
    "\n",
    "request \n",
    " [[3415  389]\n",
    " [  68  293]]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the classifier on the training data seems fairly good overall. <br>\n",
    "However, it's performance on the validation data, which is poor, seems to indicate that it's overfitting the training data. <br>\n",
    "Another way to gauge the results of a multi-label output is by computing the hamming loss. <br>\n",
    "Hamming loss is the fraction of labels that are incorrectly predicted, i.e., the fraction of the wrong labels to the total number of labels.<br> \n",
    "Hamming loss is a more desirable metric for multi-label problems than accuracy, as accuracy requires every label to match between y_true and y_pred.\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hamming_loss.html\"> Hamming Loss information </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss on train:  0.007578109589276066\n",
      "Hamming loss on val:  0.05996227062253473\n"
     ]
    }
   ],
   "source": [
    "# compute hamming loss as well\n",
    "print('Hamming loss on train: ', hamming_loss(y_train, y_pred_train))\n",
    "\n",
    "print('Hamming loss on val: ', hamming_loss(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not too bad overall. The hamming loss tells us that on the validation data, 6% of all labels applied were incorrect. <br>\n",
    "However, when you consider that many labels are very sparsely represented, we should acknowledge that it is perhaps trivial to achieve this score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test three different classifiers before tuning hyper params\n",
    "\n",
    "We will test out\n",
    "1. Multilayer Perceptron - Directly supports multi-label - <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\"> link </a>\n",
    "2. RandomForestClassifier in a OneVsRest framework.\n",
    "3. A LinearSVC wrapped in OneVsRestClassifier. <br> In essence, train a separate model to predict for each individual label. <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\"> LinearSVC link </a> and <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html\"> OneVsRest link </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import them\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_mlp = Pipeline([\n",
    "    ('msg_tokenizer', MessageTokenizer()),\n",
    "    # Count Vectorizer with Tokenizer\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    # TF-IDF Transformer\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # classifier - one classifier per label\n",
    "    ('clf', MLPClassifier(early_stopping=True)) # stop early so it doesn't keep training without improvement\n",
    "])\n",
    "\n",
    "pipeline_mlp.fit(X_train, y_train)\n",
    "y_pred_mlp = pipeline_mlp.predict(X_train)\n",
    "y_pred_val_mlp = pipeline_mlp.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss: 0.03559207197317301\n",
      "Hamming loss: 0.05580517921454296\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hamming loss: {hamming_loss(y_train, y_pred_mlp)}\")\n",
    "print(f\"Hamming loss: {hamming_loss(y_val, y_pred_val_mlp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like that neural net is overfitting - we can tell because the score is much better on the training set as compared to the validation set. However, the score on the validation set is comparable to our baseline hamming loss, 0.059"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a RandomForestClassifier, training one model per label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pipeline_rf = Pipeline([\n",
    "    ('msg_tokenizer', MessageTokenizer()),\n",
    "    # Count Vectorizer with Tokenizer\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    # TF-IDF Transformer\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # classifier - one classifier per label\n",
    "    ('clf', OneVsRestClassifier(RandomForestClassifier()))\n",
    "])\n",
    "\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "y_pred_rf = pipeline_rf.predict(X_train)\n",
    "y_pred_val_rf = pipeline_rf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss: 0.007427164898498271\n",
      "Hamming loss: 0.05741039272851998\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hamming loss: {hamming_loss(y_train, y_pred_rf)}\")\n",
    "print(f\"Hamming loss: {hamming_loss(y_val, y_pred_val_rf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomForests are also overfitting - much better score on training data than on validation data. Perhaps we could regularlize the RFs and achieve a better score on the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svc = Pipeline([\n",
    "    ('msg_tokenizer', MessageTokenizer()),\n",
    "    # Count Vectorizer with Tokenizer\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    # TF-IDF Transformer\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # classifier - one classifier per label\n",
    "    ('clf', OneVsRestClassifier(LinearSVC()))\n",
    "])\n",
    "\n",
    "pipeline_svc.fit(X_train, y_train)\n",
    "y_pred_svc = pipeline_svc.predict(X_train)\n",
    "y_pred_val_svc = pipeline_svc.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss: 0.015190524790092539\n",
      "Hamming loss: 0.05352083690619105\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hamming loss: {hamming_loss(y_train, y_pred_svc)}\")\n",
    "print(f\"Hamming loss: {hamming_loss(y_val, y_pred_val_svc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achieved our best (by a thin margin) score on the validation data set with LinearSVC. \n",
    "Since we used an SVM classifier with a linear kernel, we should be able to achieve similar performance with a Logistic Regression Model - the logistic regression model has the benefit of a built in `predict_proba()` method, which we can use to evaluate performance on individual labels. <br>\n",
    "Sklearn's linear SVM can also support `predict_proba()` by transforming decision function thresholds into probabilities - however, this can take a while to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline_log = Pipeline([\n",
    "    ('msg_tokenizer', MessageTokenizer()),\n",
    "    # Count Vectorizer with Tokenizer\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    # TF-IDF Transformer\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # classifier - one classifier per label\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "])\n",
    "\n",
    "pipeline_log.fit(X_train, y_train)\n",
    "y_pred_log = pipeline_log.predict(X_train)\n",
    "y_pred_val_log = pipeline_log.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss: 0.04656643710494944\n",
      "Hamming loss: 0.053246441433716346\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hamming loss: {hamming_loss(y_train, y_pred_log)}\")\n",
    "print(f\"Hamming loss: {hamming_loss(y_val, y_pred_val_log)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the performance of the Logistic Regression model is comparable to the LinearSVC. This is the model we will select for tuning, due to it having the best performance on our data out of the box, as well as being relatively inexpensive computationally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning hyperparameters\n",
    "In this section, we'll tune our transformation and prediction pipeline using sklearn's RandomizedSearchCV - rather than performing an exhaustive search over every combination in the hyperparameter space, we can instead take `n_iter` samples of the hyperparameter space and search for the best combination there. <p>\n",
    "    \n",
    "Each parameter combination will be fit `cv` number of times. So, for n_iter=15 and cv=3, we will fit 15 * 3 * 35 labels = 1,575 models! We expect this will run for awhile. <br>\n",
    "The RandomizedSearchCV will give us the best cross-validated score and the best param combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_scorer = make_scorer(hamming_loss, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "search_params = {\n",
    "    'msg_tokenizer__remove_stops': [False, True],\n",
    "    'msg_tokenizer__lemmatize': [False, True],\n",
    "    'tfidf__norm': [None, 'l1', 'l2'],\n",
    "    'tfidf__use_idf': [False, True],\n",
    "    'tfidf__smooth_idf': [False, True],\n",
    "    'count_vec__ngram_range': [(1,1), (1,2), (1,3), (1,4)],\n",
    "    'count_vec__max_features': [None, 100, 500, 1000],\n",
    "    'clf__estimator__dual': [False, True],\n",
    "    'clf__estimator__C': [1, 10, 50, 100],\n",
    "    'clf__estimator__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# set up the randomized search with 15 iterations (15 samples of param combinations)\n",
    "# each param combination will be fit cv=3 times. Each fit will be scored via hamming loss\n",
    "# the RandomizedSearchCV will return our best score and best param combination.\n",
    "cv_log = RandomizedSearchCV(pipeline_log, search_params, n_iter=15, cv=3, scoring=hamming_scorer, verbose=1)\n",
    "search_log = cv_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_log.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example params below.\n",
    "These are not the final parameters that we will be using. \n",
    "I ran the RandomizedSearchCV several times and achieved a better score with slightly different params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_log.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit with params\n",
    "\n",
    "pipeline_log = Pipeline([\n",
    "    ('msg_tokenizer', MessageTokenizer(remove_stops=False, lemmatize=True)),\n",
    "    # Count Vectorizer with Tokenizer\n",
    "    ('count_vec', CountVectorizer(ngram_range=(1,4), max_features=1000)),\n",
    "    # TF-IDF Transformer\n",
    "    ('tfidf', TfidfTransformer(norm='l2', use_idf=False, smooth_idf=False)),\n",
    "    # classifier - one classifier per label\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(C=10, dual=True, class_weight=None)))\n",
    "])\n",
    "\n",
    "pipeline_log.fit(X_train, y_train)\n",
    "y_pred_log = pipeline_log.predict(X_train)\n",
    "y_pred_val_log = pipeline_log.predict(X_val)\n",
    "y_prob_val_log = pipeline_log.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Hamming loss: {hamming_loss(y_train, y_pred_log)}\")\n",
    "print(f\"Hamming loss: {hamming_loss(y_val, y_pred_val_log)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have marginally improved our hamming loss on the validation data set. Additionally, hamming loss on training data is close to hamming loss on validation data, indicating that we have successfully regularlized our model. <br>\n",
    "Note that the `best_score_` is negative - this is because sklearn flips the sign for loss metrics when converting them to a scoring function. <br>\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html\"> `make_scorer()` info </a> <br>\n",
    "Now we can examine how the model is performing on individual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, col in enumerate(Y.columns):\n",
    "    print(col, '\\n', classification_report(y_val.values[:, idx], y_pred_val_log[:, idx]))\n",
    "    print(confusion_matrix(y_val.values[:, idx], y_pred_val_log[:, idx]), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model is underperforming on labels that have especially low proportions of the positive class.\n",
    "We can inspect the precision-recall trade off for each individual label to further tune our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect model output for labels where the proportion of positive instances is <= 10%\n",
    "cols_to_inspect = Y.columns[Y.mean(axis=0) <= 0.10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification metrics\n",
    "Since a multi-label problem can be regarded as a composition of binary classification tasks, we'll take some time to talk about binary classification metrics.\n",
    "\n",
    "#### Precision and Recall\n",
    "This function plots precision versus recall for different probability thresholds.\n",
    "Precision can be intuitively understood as the ratio of true positives predicted by the model to the total number of positives predicted by the model.\n",
    "Recall can be intuitively understood as the ratio of true positives predicted by the model to the total number of true positives in the dataset.\n",
    "    \n",
    "There is tension between precision and recall - in general, an increase in precision results in a decrease in recall.\n",
    "The desired balance between the two, depending on your needs and the goal of your model, can be attained by setting the specific decision function threshold at which your model assigns an instance to the positive class.\n",
    "In short, if you raise the threshold at which your model classifies instances as belonging to the positive class, thereby reducing the number of true negatives that it misclassifies as positives,  you raise the number of true positives that your model misclassifies as negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fxns for charting binary classification\n",
    "\n",
    "def precision_recall_vs_thresholds(y_true, y_scores, label='Class', plot_grid=False):\n",
    "    \"\"\"Plot precision and recall vs threshold values of y.\n",
    "    \n",
    "    Args:\n",
    "        y_true (array): binary indication of target variable's true state\n",
    "        y_scores (array): model's score for each instance\n",
    "        plot_grid (bool): whether or not to plot gridlines\n",
    "        \n",
    "    Returns:\n",
    "        ax: matplotlib axes object containing the precision recall chart.\n",
    "    \"\"\"\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    ax.plot(thresholds, precisions[:-1], 'b--', label='Precision')\n",
    "    ax.plot(thresholds, recalls[:-1], 'g-', label='Recall')\n",
    "    ax.set_xlabel('Thresholds')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.legend(loc='upper right')\n",
    "    \n",
    "    if plot_grid:\n",
    "        threshs = np.round(np.arange(0.0, 1.05, 0.05), 2)\n",
    "        for thr in threshs:\n",
    "            ax.axvline(thr, alpha=0.15)\n",
    "            ax.axhline(thr, alpha=0.15)\n",
    "        ax.set_xticks(threshs)\n",
    "        ax.set_xticklabels(threshs, rotation=90)\n",
    "        ax.set_yticks(threshs)\n",
    "        ax.set_yticklabels(threshs)\n",
    "    \n",
    "    ax.set_ylabel('probability')\n",
    "    ax.set_title(f'Precision vs Recall Curves for p({label}=1) Thresholds')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_val_log.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, col in enumerate(Y.columns):\n",
    "    if col in cols_to_inspect:\n",
    "        y_scores = y_prob_val_log[:, idx]\n",
    "        y_true = y_val.values[:, idx]\n",
    "        precision_recall_vs_thresholds(y_true, y_scores, label=col, plot_grid=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reviewing the precision-recall charts, we can set custom probability thresholds per label. The reasoning here is that, since our positive class instances are very sparsely represented and signify people in some distress, we are more interested in capturing as many true positives as we can (increasing our recall). <br> This will come at the expense of decreasing our precision, meaning that we will falsely predict more positive instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_thresh = {\n",
    "    'offer': 0.025,\n",
    "    'medical_help': 0.20,\n",
    "    'medical_products': 0.20,\n",
    "    'search_and_rescue': 0.15,\n",
    "    'security': 0.05,\n",
    "    'military': 0.125,\n",
    "    'water': 0.20,\n",
    "    'shelter': 0.20,\n",
    "    'clothing': 0.10,\n",
    "    'money': 0.10,\n",
    "    'missing_people': 0.075,\n",
    "    'refugees': 0.15,\n",
    "    'death': 0.20,\n",
    "    'infrastructure_related': 0.15,\n",
    "    'transport': 0.15,\n",
    "    'buildings': 0.20,\n",
    "    'electricity': 0.15,\n",
    "    'tools': 0.10,\n",
    "    'hospitals': 0.15,\n",
    "    'shops': 0.10,\n",
    "    'aid_centers': 0.05,\n",
    "    'other_infrastructure': 0.10,\n",
    "    'floods': 0.15,\n",
    "    'storm': 0.15,\n",
    "    'fire': 0.05,\n",
    "    'earthquake': 0.15,\n",
    "    'cold': 0.15,\n",
    "    'other_weather': 0.15\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_thresh(estimator, X, labels_array, thresholds):\n",
    "    \"\"\"Return binary classification based on custom thresholds.\n",
    "    \n",
    "    Args:\n",
    "        estimator: an object capable of predict() and predict_proba() methods\n",
    "        X: data to predict on \n",
    "        labels_array: array/list of label names\n",
    "        thresholds (dict): dictionary of label:threshold values\n",
    "        \n",
    "    Returns:\n",
    "        y_pred (arr): binary array of prediction based on custom threshold.    \n",
    "    \"\"\"\n",
    "    y_prob = estimator.predict_proba(X)\n",
    "    # placeholder for labels that do not have custom thresholds\n",
    "    y_pred = estimator.predict(X)    \n",
    "    for idx, label in enumerate(labels_array):\n",
    "        if label in thresholds.keys():\n",
    "            # replace the default prediction with the custom prediction\n",
    "            y_pred[:, idx] = y_prob[:, idx] >= thresholds[label] * 1 # convert bool to int\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val_custom = predict_with_thresh(pipeline_log, X_val, Y.columns, custom_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, col in enumerate(Y.columns):\n",
    "    print(col, '\\n', 'custom thresholds: ', classification_report(y_val.values[:, idx], y_pred_val_custom[:, idx]))\n",
    "    print(confusion_matrix(y_val.values[:, idx], y_pred_val_custom[:, idx]), '\\n')\n",
    "    print('\\n', 'normal thresholds: ', classification_report(y_val.values[:, idx], y_pred_val_log[:, idx]))\n",
    "    print(confusion_matrix(y_val.values[:, idx], y_pred_val_log[:, idx]), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the output of the above, you can see that we have increased the number of true positive classifications for labels with sparse representation. This has come at the cost of increasing our number of false positives. However, when you consider the context of the problem, it is perhaps better to marginally increase the number of false positives classified if it means capturing more true instances of people in need. <br>\n",
    "In all likelihood, these classifications would be reviewed by somebody attempting to orchestrate aid efforts - better to slightly increase the noise if it means identifying more of those in need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's test out our model on the last holdout data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with custom thresholds\n",
    "y_pred_test_custom = predict_with_thresh(pipeline_log, X_test, Y.columns, custom_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Hamming loss on test: {hamming_loss(y_test, y_pred_test_custom)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, col in enumerate(Y.columns):\n",
    "    print(col, '\\n', classification_report(y_test.values[:, idx], y_pred_test_custom[:, idx]))\n",
    "    print(confusion_matrix(y_test.values[:, idx], y_pred_test_custom[:, idx]), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pipeline_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Hamming loss on test: {hamming_loss(y_test, y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is not perfect, but is both fast and fairly good at predicting the required labels, only missing 5% of labels on the holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
