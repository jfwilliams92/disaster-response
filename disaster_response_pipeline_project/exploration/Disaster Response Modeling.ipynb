{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaster Reponse Pipeline Creation \n",
    "\n",
    "\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jwilliams1\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\python.exe'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys; sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-multilearn\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/1f/e6ff649c72a1cdf2c7a1d31eb21705110ce1c5d3e7e26b2cc300e1637272/scikit_multilearn-0.2.0-py3-none-any.whl (89kB)\n",
      "Installing collected packages: scikit-multilearn\n",
      "Successfully installed scikit-multilearn-0.2.0\n",
      "Collecting arf\n",
      "  Downloading https://files.pythonhosted.org/packages/5f/93/445d180895ee651800fd3e630fa7a511e4701f6ef455acb8e74075f1ca8e/arf-2.5.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.3 in c:\\users\\jwilliams1\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from arf) (1.15.4)\n",
      "Requirement already satisfied: h5py>=2.2 in c:\\users\\jwilliams1\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from arf) (2.8.0)\n",
      "Requirement already satisfied: six in c:\\users\\jwilliams1\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from h5py>=2.2->arf) (1.13.0)\n",
      "Installing collected packages: arf\n",
      "Successfully installed arf-2.5.1\n"
     ]
    }
   ],
   "source": [
    "! {sys.executable} -m pip install scikit-multilearn\n",
    "! {sys.executable} -m pip install arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jwilliams1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jwilliams1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jwilliams1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jwilliams1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from skmultilearn.model_selection import iterative_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterMessages.db')\n",
    "df = pd.read_sql('SELECT * FROM CleanMessages', engine)\n",
    "\n",
    "# define variables. X is input, Y is target\n",
    "X = df['message']\n",
    "Y = df.drop(['id', 'message', 'original', 'genre'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the 'child alone' tag because there are no messages with this tag.\n",
    "Y = Y.drop('child_alone', axis=1)\n",
    "\n",
    "# replace 2's with 1's in the related field\n",
    "Y.loc[Y.related == 2, 'related'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products      ...        \\\n",
       "0        0      0            0             0                 0      ...         \n",
       "1        0      0            1             0                 0      ...         \n",
       "2        0      0            0             0                 0      ...         \n",
       "3        1      0            1             0                 1      ...         \n",
       "4        0      0            0             0                 0      ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "4            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "4           0     0              0              0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many in original data are related=2\n",
    "(df.related == 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26216,), (26216, 35))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the shape of the data\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have 26k messages with 35 possible labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization class to process the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that will allow a treebank POS tag to be converted into a WordNet\n",
    "# POS Tag so the lemmatizer will understand it\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    # default to Noun \n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement a custom transformer with hyperparameters in order to determine if removing stop words and/or lemmatizing words will have a positive effect on classification efficacy.\n",
    "This custom transformer follows sklearn's rules for transformers so that it can be used in our processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a custom transformer to determine if removing stops and/or lemmatizing improves model performance\n",
    "\n",
    "class MessageTokenizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, remove_stops=True, lemmatize=True):\n",
    "        self.remove_stops = remove_stops\n",
    "        self.lemmatize = lemmatize\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        \n",
    "        # iterate over supplied messages\n",
    "        for text in X: \n",
    "            # remove all non-alphanumeric characters\n",
    "            text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "              \n",
    "            # lower and strip whitespace\n",
    "            text = text.lower().strip()\n",
    "    \n",
    "            # tokenize words - nltk.tokenize.word_tokenize\n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.lemmatize:\n",
    "                # tag words with Part of Speech - list of (word, POS) tuples \n",
    "                # nltk.pos_tag()\n",
    "                words_with_pos_tag = pos_tag(words)\n",
    "                \n",
    "                if self.remove_stops:\n",
    "                    # remove stop words\n",
    "                    # stop_words = nlt.corpus.stopwords of 'english' language\n",
    "                    words_with_pos_tag = [word for word in words_with_pos_tag if word[0] not in stop_words]\n",
    "                \n",
    "                # change pos tags to wordnet pos tags for lemmatizer\n",
    "                words_with_wordnet_tag = []\n",
    "    \n",
    "                for word_with_tag in words_with_pos_tag:\n",
    "                    word, tag = word_with_tag\n",
    "                    tag = get_wordnet_pos(tag)\n",
    "                    words_with_wordnet_tag.append((word, tag))\n",
    "\n",
    "                # lemmatize\n",
    "                lemm = WordNetLemmatizer()\n",
    "                # unpack the (word, pos) tuple into the Lemmatizer to give better lemmatization \n",
    "                # lemmatization is more effective when it knows the correct part of speech\n",
    "                words = [lemm.lemmatize(*w) for w in words_with_wordnet_tag]\n",
    "                \n",
    "            else:\n",
    "                if self.remove_stops:\n",
    "                    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "            # join cleaned words back into single document\n",
    "            X_transformed.append(' '.join(words))\n",
    "        \n",
    "        return X_transformed    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show off the custom transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We would not want these words taking up space in our database, or taking up valuable processing time. For this, we can remove them easily, by storing a list of words that you consider to be stop words',\n",
       " \"Here is another example of words. Isn't it great how words are?\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"We would not want these words taking up space in our database, or taking up valuable processing time. For this, we can remove them easily, by storing a list of words that you consider to be stop words\"]\n",
    "text.append(\"Here is another example of words. Isn't it great how words are?\")\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we would not want these word take up space in our database or take up valuable processing time for this we can remove them easily by store a list of word that you consider to be stop word',\n",
       " 'here be another example of word isn t it great how word be']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MessageTokenizer(remove_stops=False, lemmatize=True).transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a first machine learning pipeline\n",
    "A pipeline allows us to wrap all of our data transformation steps into a neat little package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('msg_tokenizer', MessageTokenizer()),\n",
    "    # Count Vectorizer with Tokenizer\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    # TF-IDF Transformer\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # classifier - one classifier per label\n",
    "    ('clf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a multilabel classification, I looked into the iterative train-test-split supplied by skmultilearn.\n",
    "The idea with the iterative train test split is that in theory it can provide better label representation for mutli label problems. Here I will compare whether this train test split results in appropriate label representation for the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the proportion of labels in the original data\n",
    "compare = pd.DataFrame(Y.mean(axis=0), columns=['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.766478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.170659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.004501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.414251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.079493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset\n",
       "related       0.766478\n",
       "request       0.170659\n",
       "offer         0.004501\n",
       "aid_related   0.414251\n",
       "medical_help  0.079493"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employ skmultilearn's iterative train test split.\n",
    "# have to reshape the X values to be multidimensional since that's what this expects\n",
    "\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X.values.reshape(-1,1), Y.values, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to see how the iterative split did with label proportions\n",
    "compare['train_set'] = y_train.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal train test split - how does it compare\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare['normal_split'] = y_train2.values.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train_set</th>\n",
       "      <th>normal_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.766478</td>\n",
       "      <td>0.766453</td>\n",
       "      <td>0.767521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.170659</td>\n",
       "      <td>0.135388</td>\n",
       "      <td>0.170430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.004221</td>\n",
       "      <td>0.004883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.414251</td>\n",
       "      <td>0.414251</td>\n",
       "      <td>0.415166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.079493</td>\n",
       "      <td>0.087784</td>\n",
       "      <td>0.080714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.050084</td>\n",
       "      <td>0.053148</td>\n",
       "      <td>0.049690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.027617</td>\n",
       "      <td>0.028532</td>\n",
       "      <td>0.027973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.017966</td>\n",
       "      <td>0.019327</td>\n",
       "      <td>0.017750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.032804</td>\n",
       "      <td>0.041247</td>\n",
       "      <td>0.032703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.063778</td>\n",
       "      <td>0.062608</td>\n",
       "      <td>0.063981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.111497</td>\n",
       "      <td>0.097905</td>\n",
       "      <td>0.111688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.088267</td>\n",
       "      <td>0.085647</td>\n",
       "      <td>0.089157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.015449</td>\n",
       "      <td>0.013885</td>\n",
       "      <td>0.015970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.023039</td>\n",
       "      <td>0.023853</td>\n",
       "      <td>0.022785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.011367</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>0.011342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.033377</td>\n",
       "      <td>0.037992</td>\n",
       "      <td>0.032855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.045545</td>\n",
       "      <td>0.049588</td>\n",
       "      <td>0.046180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.131446</td>\n",
       "      <td>0.124352</td>\n",
       "      <td>0.130556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.065037</td>\n",
       "      <td>0.068508</td>\n",
       "      <td>0.064541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.045812</td>\n",
       "      <td>0.048215</td>\n",
       "      <td>0.046435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.050860</td>\n",
       "      <td>0.051114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.020293</td>\n",
       "      <td>0.020293</td>\n",
       "      <td>0.020446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.006065</td>\n",
       "      <td>0.006713</td>\n",
       "      <td>0.005696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.010795</td>\n",
       "      <td>0.011443</td>\n",
       "      <td>0.010681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.004323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.011787</td>\n",
       "      <td>0.012410</td>\n",
       "      <td>0.011698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.043904</td>\n",
       "      <td>0.046842</td>\n",
       "      <td>0.043485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.278341</td>\n",
       "      <td>0.278354</td>\n",
       "      <td>0.276218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.082202</td>\n",
       "      <td>0.093429</td>\n",
       "      <td>0.081324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.093187</td>\n",
       "      <td>0.091954</td>\n",
       "      <td>0.092361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.010757</td>\n",
       "      <td>0.011850</td>\n",
       "      <td>0.010528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.093645</td>\n",
       "      <td>0.081528</td>\n",
       "      <td>0.094650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.020217</td>\n",
       "      <td>0.021971</td>\n",
       "      <td>0.019377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.052487</td>\n",
       "      <td>0.058183</td>\n",
       "      <td>0.052284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.193584</td>\n",
       "      <td>0.157919</td>\n",
       "      <td>0.192249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         dataset  train_set  normal_split\n",
       "related                 0.766478   0.766453      0.767521\n",
       "request                 0.170659   0.135388      0.170430\n",
       "offer                   0.004501   0.004221      0.004883\n",
       "aid_related             0.414251   0.414251      0.415166\n",
       "medical_help            0.079493   0.087784      0.080714\n",
       "medical_products        0.050084   0.053148      0.049690\n",
       "search_and_rescue       0.027617   0.028532      0.027973\n",
       "security                0.017966   0.019327      0.017750\n",
       "military                0.032804   0.041247      0.032703\n",
       "water                   0.063778   0.062608      0.063981\n",
       "food                    0.111497   0.097905      0.111688\n",
       "shelter                 0.088267   0.085647      0.089157\n",
       "clothing                0.015449   0.013885      0.015970\n",
       "money                   0.023039   0.023853      0.022785\n",
       "missing_people          0.011367   0.011749      0.011342\n",
       "refugees                0.033377   0.037992      0.032855\n",
       "death                   0.045545   0.049588      0.046180\n",
       "other_aid               0.131446   0.124352      0.130556\n",
       "infrastructure_related  0.065037   0.068508      0.064541\n",
       "transport               0.045812   0.048215      0.046435\n",
       "buildings               0.050847   0.050860      0.051114\n",
       "electricity             0.020293   0.020293      0.020446\n",
       "tools                   0.006065   0.006713      0.005696\n",
       "hospitals               0.010795   0.011443      0.010681\n",
       "shops                   0.004577   0.004628      0.004323\n",
       "aid_centers             0.011787   0.012410      0.011698\n",
       "other_infrastructure    0.043904   0.046842      0.043485\n",
       "weather_related         0.278341   0.278354      0.276218\n",
       "floods                  0.082202   0.093429      0.081324\n",
       "storm                   0.093187   0.091954      0.092361\n",
       "fire                    0.010757   0.011850      0.010528\n",
       "earthquake              0.093645   0.081528      0.094650\n",
       "cold                    0.020217   0.021971      0.019377\n",
       "other_weather           0.052487   0.058183      0.052284\n",
       "direct_report           0.193584   0.157919      0.192249"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset - normalsplit</th>\n",
       "      <th>dataset - iterative split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.035271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.008290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.001360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.008443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.001170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.013592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.002619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.001564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.004616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.004043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.007095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.003471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.002403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.002937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.011227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.001233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.001093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.012117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.001755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.005696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.035665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        dataset - normalsplit  dataset - iterative split\n",
       "related                              0.001043                   0.000025\n",
       "request                              0.000229                   0.035271\n",
       "offer                                0.000381                   0.000280\n",
       "aid_related                          0.000915                   0.000000\n",
       "medical_help                         0.001221                   0.008290\n",
       "medical_products                     0.000394                   0.003064\n",
       "search_and_rescue                    0.000356                   0.000915\n",
       "security                             0.000216                   0.001360\n",
       "military                             0.000102                   0.008443\n",
       "water                                0.000203                   0.001170\n",
       "food                                 0.000191                   0.013592\n",
       "shelter                              0.000890                   0.002619\n",
       "clothing                             0.000521                   0.001564\n",
       "money                                0.000254                   0.000814\n",
       "missing_people                       0.000025                   0.000381\n",
       "refugees                             0.000521                   0.004616\n",
       "death                                0.000636                   0.004043\n",
       "other_aid                            0.000890                   0.007095\n",
       "infrastructure_related               0.000496                   0.003471\n",
       "transport                            0.000623                   0.002403\n",
       "buildings                            0.000267                   0.000013\n",
       "electricity                          0.000153                   0.000000\n",
       "tools                                0.000369                   0.000648\n",
       "hospitals                            0.000114                   0.000648\n",
       "shops                                0.000254                   0.000051\n",
       "aid_centers                          0.000089                   0.000623\n",
       "other_infrastructure                 0.000420                   0.002937\n",
       "weather_related                      0.002123                   0.000013\n",
       "floods                               0.000877                   0.011227\n",
       "storm                                0.000826                   0.001233\n",
       "fire                                 0.000229                   0.001093\n",
       "earthquake                           0.001004                   0.012117\n",
       "cold                                 0.000839                   0.001755\n",
       "other_weather                        0.000203                   0.005696\n",
       "direct_report                        0.001335                   0.035665"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = pd.DataFrame(compare['dataset'] - compare['normal_split'])\n",
    "diff.columns = ['dataset - normalsplit']\n",
    "diff['dataset - iterative split'] = compare['dataset'] - compare['train_set']\n",
    "diff = diff.abs()\n",
    "\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "diff.plot(kind='barh', ax=ax)\n",
    "plt.xlabel('Abs Diff in label proportion from original')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the normal train-test-split does a fine, if not better job, of capturing nearly the same proportion of labels as in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('msg_tokenizer', MessageTokenizer(lemmatize=True, remove_stops=True)), ('count_vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the pipeline!\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MessageTokenizer(remove_stops=True, lemmatize=True).transform(X_train.reshape(-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the fitted model on the train data\n",
    "We'll save the test data for the very end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = pipeline.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      4613\n",
      "         1.0       0.99      0.99      0.99     15049\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.99      0.99      0.99     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "request \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99     16574\n",
      "         1.0       0.92      1.00      0.96      3088\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.96      0.99      0.98     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "offer \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     19601\n",
      "         1.0       0.76      1.00      0.87        61\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       0.88      1.00      0.93     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "aid_related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.98     11856\n",
      "         1.0       0.96      1.00      0.98      7806\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     19662\n",
      "   macro avg       0.98      0.98      0.98     19662\n",
      "weighted avg       0.98      0.98      0.98     19662\n",
      "\n",
      "medical_help \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99     18340\n",
      "         1.0       0.84      1.00      0.91      1322\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.92      0.99      0.95     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "medical_products \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     18842\n",
      "         1.0       0.82      1.00      0.90       820\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.91      1.00      0.95     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "search_and_rescue \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     19227\n",
      "         1.0       0.79      1.00      0.88       435\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.90      1.00      0.94     19662\n",
      "weighted avg       1.00      0.99      0.99     19662\n",
      "\n",
      "security \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     19410\n",
      "         1.0       0.72      1.00      0.84       252\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       0.86      1.00      0.92     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "military \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     19139\n",
      "         1.0       0.81      1.00      0.89       523\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.90      1.00      0.94     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "water \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     18536\n",
      "         1.0       0.90      1.00      0.95      1126\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.95      1.00      0.97     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "food \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     17612\n",
      "         1.0       0.94      1.00      0.97      2050\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.97      1.00      0.98     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "shelter \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     18089\n",
      "         1.0       0.91      1.00      0.95      1573\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.96      1.00      0.97     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "clothing \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     19407\n",
      "         1.0       0.82      1.00      0.90       255\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       0.91      1.00      0.95     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "money \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     19302\n",
      "         1.0       0.77      1.00      0.87       360\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.89      1.00      0.93     19662\n",
      "weighted avg       1.00      0.99      0.99     19662\n",
      "\n",
      "missing_people \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     19505\n",
      "         1.0       0.72      1.00      0.84       157\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       0.86      1.00      0.92     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "refugees \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     19121\n",
      "         1.0       0.81      1.00      0.90       541\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.91      1.00      0.95     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "death \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     18922\n",
      "         1.0       0.85      1.00      0.92       740\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.93      1.00      0.96     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "other_aid \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99     17465\n",
      "         1.0       0.85      1.00      0.92      2197\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     19662\n",
      "   macro avg       0.92      0.99      0.95     19662\n",
      "weighted avg       0.98      0.98      0.98     19662\n",
      "\n",
      "infrastructure_related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99     18634\n",
      "         1.0       0.79      1.00      0.88      1028\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.89      0.99      0.94     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "transport \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     18931\n",
      "         1.0       0.81      1.00      0.90       731\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.91      0.99      0.95     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "buildings \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     18816\n",
      "         1.0       0.86      1.00      0.93       846\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.93      1.00      0.96     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "electricity \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     19328\n",
      "         1.0       0.82      1.00      0.90       334\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       0.91      1.00      0.95     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "tools \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     19588\n",
      "         1.0       0.67      1.00      0.80        74\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       0.83      1.00      0.90     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "hospitals \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     19508\n",
      "         1.0       0.70      1.00      0.83       154\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       0.85      1.00      0.91     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "shops \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     19588\n",
      "         1.0       0.80      1.00      0.89        74\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       0.90      1.00      0.94     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "aid_centers \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     19484\n",
      "         1.0       0.75      1.00      0.86       178\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       0.88      1.00      0.93     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "other_infrastructure \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99     18977\n",
      "         1.0       0.78      1.00      0.87       685\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.89      0.99      0.93     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "weather_related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99     14461\n",
      "         1.0       0.95      1.00      0.97      5201\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.97      0.99      0.98     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "floods \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     18228\n",
      "         1.0       0.90      1.00      0.95      1434\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.95      1.00      0.97     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "storm \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     17974\n",
      "         1.0       0.93      1.00      0.96      1688\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.96      1.00      0.98     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "fire \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     19490\n",
      "         1.0       0.81      1.00      0.89       172\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       0.90      1.00      0.95     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "earthquake \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     17921\n",
      "         1.0       0.95      0.99      0.97      1741\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.97      0.99      0.98     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "cold \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     19330\n",
      "         1.0       0.82      1.00      0.90       332\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       0.91      1.00      0.95     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "other_weather \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99     18830\n",
      "         1.0       0.79      1.00      0.89       832\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.90      0.99      0.94     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "direct_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99     16183\n",
      "         1.0       0.91      1.00      0.95      3479\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     19662\n",
      "   macro avg       0.96      0.99      0.97     19662\n",
      "weighted avg       0.98      0.98      0.98     19662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iterate thru all the labels and check the accuracy on each label\n",
    "\n",
    "y_pred = pd.DataFrame(y_pred, columns=Y.columns)\n",
    "y_train = pd.DataFrame(y_train, columns=Y.columns)\n",
    "\n",
    "for col in Y.columns:\n",
    "    print(col, '\\n', classification_report(y_pred[col], y_train[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related \n",
      " [[ 4453    83]\n",
      " [   64 15062]]\n",
      "\n",
      "\n",
      "request \n",
      " [[16271   237]\n",
      " [   11  3143]]\n",
      "\n",
      "\n",
      "offer \n",
      " [[19569    28]\n",
      " [    0    65]]\n",
      "\n",
      "\n",
      "aid_related \n",
      " [[11440   299]\n",
      " [   17  7906]]\n",
      "\n",
      "\n",
      "medical_help \n",
      " [[18099   265]\n",
      " [    1  1297]]\n",
      "\n",
      "\n",
      "medical_products \n",
      " [[18678   155]\n",
      " [    1   828]]\n",
      "\n",
      "\n",
      "search_and_rescue \n",
      " [[19129   109]\n",
      " [    2   422]]\n",
      "\n",
      "\n",
      "security \n",
      " [[19294   102]\n",
      " [    2   264]]\n",
      "\n",
      "\n",
      "military \n",
      " [[18989   113]\n",
      " [    0   560]]\n",
      "\n",
      "\n",
      "water \n",
      " [[18400    77]\n",
      " [    0  1185]]\n",
      "\n",
      "\n",
      "food \n",
      " [[17429   151]\n",
      " [    2  2080]]\n",
      "\n",
      "\n",
      "shelter \n",
      " [[17930   166]\n",
      " [    4  1562]]\n",
      "\n",
      "\n",
      "clothing \n",
      " [[19351    57]\n",
      " [    0   254]]\n",
      "\n",
      "\n",
      "money \n",
      " [[19199   102]\n",
      " [    1   360]]\n",
      "\n",
      "\n",
      "missing_people \n",
      " [[19432    55]\n",
      " [    1   174]]\n",
      "\n",
      "\n",
      "refugees \n",
      " [[18996   136]\n",
      " [    1   529]]\n",
      "\n",
      "\n",
      "death \n",
      " [[18746   151]\n",
      " [    1   764]]\n",
      "\n",
      "\n",
      "other_aid \n",
      " [[17083   413]\n",
      " [    5  2161]]\n",
      "\n",
      "\n",
      "infrastructure_related \n",
      " [[18360   267]\n",
      " [    1  1034]]\n",
      "\n",
      "\n",
      "transport \n",
      " [[18748   184]\n",
      " [    2   728]]\n",
      "\n",
      "\n",
      "buildings \n",
      " [[18637   168]\n",
      " [    1   856]]\n",
      "\n",
      "\n",
      "electricity \n",
      " [[19268    82]\n",
      " [    0   312]]\n",
      "\n",
      "\n",
      "tools \n",
      " [[19550    28]\n",
      " [    0    84]]\n",
      "\n",
      "\n",
      "hospitals \n",
      " [[19448    58]\n",
      " [    0   156]]\n",
      "\n",
      "\n",
      "shops \n",
      " [[19567    27]\n",
      " [    0    68]]\n",
      "\n",
      "\n",
      "aid_centers \n",
      " [[19420    56]\n",
      " [    0   186]]\n",
      "\n",
      "\n",
      "other_infrastructure \n",
      " [[18792   182]\n",
      " [    1   687]]\n",
      "\n",
      "\n",
      "weather_related \n",
      " [[14102   272]\n",
      " [   17  5271]]\n",
      "\n",
      "\n",
      "floods \n",
      " [[18002   182]\n",
      " [    5  1473]]\n",
      "\n",
      "\n",
      "storm \n",
      " [[17805   171]\n",
      " [    4  1682]]\n",
      "\n",
      "\n",
      "fire \n",
      " [[19435    55]\n",
      " [    0   172]]\n",
      "\n",
      "\n",
      "earthquake \n",
      " [[17805    78]\n",
      " [    9  1770]]\n",
      "\n",
      "\n",
      "cold \n",
      " [[19264    75]\n",
      " [    0   323]]\n",
      "\n",
      "\n",
      "other_weather \n",
      " [[18632   197]\n",
      " [    2   831]]\n",
      "\n",
      "\n",
      "direct_report \n",
      " [[15842   291]\n",
      " [    9  3520]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for col in Y.columns:\n",
    "    print(col, '\\n', confusion_matrix(y_pred[col], y_train[col]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the classifier on the training data seems fairly good overall.\n",
    "Another way to gauge the results of a multi-label output is by computing the hamming loss.\n",
    "Hamming loss is the fraction of labels that are incorrectly predicted, i.e., the fraction of the wrong labels to the total number of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss:  0.007662350872604153\n"
     ]
    }
   ],
   "source": [
    "# compute hamming loss as well\n",
    "from sklearn.metrics import hamming_loss, make_scorer\n",
    "\n",
    "# drop related column while measuring this because there are some rows with related=2\n",
    "print('Hamming loss: ', hamming_loss(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('msg_tokenizer',\n",
       "                 MessageTokenizer(lemmatize=True, remove_stops=True)),\n",
       "                ('count_vec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_ac...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit and predict on the iterative split to see if it performs better\n",
    "pipeline2 = Pipeline([\n",
    "    ('msg_tokenizer', MessageTokenizer()),\n",
    "    # Count Vectorizer with Tokenizer\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    # TF-IDF Transformer\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # classifier - one classifier per label\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "X_train2, y_train2, X_test2, y_test2 = iterative_train_test_split(X.values.reshape(-1,1), Y.values, test_size = 0.25)\n",
    "\n",
    "pipeline2.fit(X_train.values.reshape(-1,), y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      4395\n",
      "           1       0.97      0.96      0.97     15267\n",
      "\n",
      "    accuracy                           0.95     19662\n",
      "   macro avg       0.92      0.94      0.93     19662\n",
      "weighted avg       0.95      0.95      0.95     19662\n",
      "\n",
      "request \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     17459\n",
      "           1       0.79      0.96      0.86      2203\n",
      "\n",
      "    accuracy                           0.97     19662\n",
      "   macro avg       0.89      0.96      0.92     19662\n",
      "weighted avg       0.97      0.97      0.97     19662\n",
      "\n",
      "offer \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19614\n",
      "           1       0.53      1.00      0.70        48\n",
      "\n",
      "    accuracy                           1.00     19662\n",
      "   macro avg       0.77      1.00      0.85     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "aid_related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93     12466\n",
      "           1       0.85      0.96      0.90      7196\n",
      "\n",
      "    accuracy                           0.92     19662\n",
      "   macro avg       0.91      0.93      0.92     19662\n",
      "weighted avg       0.93      0.92      0.92     19662\n",
      "\n",
      "medical_help \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     18572\n",
      "           1       0.63      0.99      0.77      1090\n",
      "\n",
      "    accuracy                           0.97     19662\n",
      "   macro avg       0.81      0.98      0.88     19662\n",
      "weighted avg       0.98      0.97      0.97     19662\n",
      "\n",
      "medical_products \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     18993\n",
      "           1       0.64      0.99      0.77       669\n",
      "\n",
      "    accuracy                           0.98     19662\n",
      "   macro avg       0.82      0.99      0.88     19662\n",
      "weighted avg       0.99      0.98      0.98     19662\n",
      "\n",
      "search_and_rescue \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     19323\n",
      "           1       0.59      1.00      0.74       339\n",
      "\n",
      "    accuracy                           0.99     19662\n",
      "   macro avg       0.79      0.99      0.87     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "security \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     19446\n",
      "           1       0.58      0.99      0.73       216\n",
      "\n",
      "    accuracy                           0.99     19662\n",
      "   macro avg       0.79      0.99      0.86     19662\n",
      "weighted avg       1.00      0.99      0.99     19662\n",
      "\n",
      "military \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     19112\n",
      "           1       0.67      0.99      0.80       550\n",
      "\n",
      "    accuracy                           0.99     19662\n",
      "   macro avg       0.83      0.99      0.90     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "water \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     18667\n",
      "           1       0.79      0.97      0.87       995\n",
      "\n",
      "    accuracy                           0.99     19662\n",
      "   macro avg       0.90      0.98      0.93     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "food \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     18092\n",
      "           1       0.78      0.97      0.87      1570\n",
      "\n",
      "    accuracy                           0.98     19662\n",
      "   macro avg       0.89      0.97      0.93     19662\n",
      "weighted avg       0.98      0.98      0.98     19662\n",
      "\n",
      "shelter \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     18412\n",
      "           1       0.72      0.98      0.83      1250\n",
      "\n",
      "    accuracy                           0.97     19662\n",
      "   macro avg       0.86      0.98      0.91     19662\n",
      "weighted avg       0.98      0.97      0.98     19662\n",
      "\n",
      "clothing \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19487\n",
      "           1       0.64      0.97      0.77       175\n",
      "\n",
      "    accuracy                           0.99     19662\n",
      "   macro avg       0.82      0.98      0.88     19662\n",
      "weighted avg       1.00      0.99      1.00     19662\n",
      "\n",
      "money \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     19373\n",
      "           1       0.61      0.99      0.75       289\n",
      "\n",
      "    accuracy                           0.99     19662\n",
      "   macro avg       0.80      0.99      0.87     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "missing_people \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19528\n",
      "           1       0.61      0.99      0.76       134\n",
      "\n",
      "    accuracy                           1.00     19662\n",
      "   macro avg       0.81      0.99      0.88     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "refugees \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     19200\n",
      "           1       0.62      0.99      0.76       462\n",
      "\n",
      "    accuracy                           0.99     19662\n",
      "   macro avg       0.81      0.99      0.88     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "death \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     19025\n",
      "           1       0.65      1.00      0.79       637\n",
      "\n",
      "    accuracy                           0.98     19662\n",
      "   macro avg       0.83      0.99      0.89     19662\n",
      "weighted avg       0.99      0.98      0.98     19662\n",
      "\n",
      "other_aid \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     18116\n",
      "           1       0.63      0.99      0.77      1546\n",
      "\n",
      "    accuracy                           0.95     19662\n",
      "   macro avg       0.82      0.97      0.87     19662\n",
      "weighted avg       0.97      0.95      0.96     19662\n",
      "\n",
      "infrastructure_related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     18847\n",
      "           1       0.61      1.00      0.76       815\n",
      "\n",
      "    accuracy                           0.97     19662\n",
      "   macro avg       0.81      0.98      0.87     19662\n",
      "weighted avg       0.98      0.97      0.98     19662\n",
      "\n",
      "transport \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     19081\n",
      "           1       0.62      0.99      0.76       581\n",
      "\n",
      "    accuracy                           0.98     19662\n",
      "   macro avg       0.81      0.99      0.88     19662\n",
      "weighted avg       0.99      0.98      0.98     19662\n",
      "\n",
      "buildings \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     19004\n",
      "           1       0.65      0.99      0.79       658\n",
      "\n",
      "    accuracy                           0.98     19662\n",
      "   macro avg       0.83      0.99      0.89     19662\n",
      "weighted avg       0.99      0.98      0.98     19662\n",
      "\n",
      "electricity \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     19426\n",
      "           1       0.59      1.00      0.74       236\n",
      "\n",
      "    accuracy                           0.99     19662\n",
      "   macro avg       0.80      1.00      0.87     19662\n",
      "weighted avg       1.00      0.99      0.99     19662\n",
      "\n",
      "tools \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19590\n",
      "           1       0.53      1.00      0.69        72\n",
      "\n",
      "    accuracy                           1.00     19662\n",
      "   macro avg       0.76      1.00      0.84     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "hospitals \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     19539\n",
      "           1       0.55      1.00      0.71       123\n",
      "\n",
      "    accuracy                           0.99     19662\n",
      "   macro avg       0.78      1.00      0.85     19662\n",
      "weighted avg       1.00      0.99      1.00     19662\n",
      "\n",
      "shops \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19615\n",
      "           1       0.54      1.00      0.70        47\n",
      "\n",
      "    accuracy                           1.00     19662\n",
      "   macro avg       0.77      1.00      0.85     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "aid_centers \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     19519\n",
      "           1       0.59      1.00      0.74       143\n",
      "\n",
      "    accuracy                           0.99     19662\n",
      "   macro avg       0.80      1.00      0.87     19662\n",
      "weighted avg       1.00      0.99      1.00     19662\n",
      "\n",
      "other_infrastructure \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     19114\n",
      "           1       0.60      1.00      0.75       548\n",
      "\n",
      "    accuracy                           0.98     19662\n",
      "   macro avg       0.80      0.99      0.87     19662\n",
      "weighted avg       0.99      0.98      0.98     19662\n",
      "\n",
      "weather_related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97     15002\n",
      "           1       0.83      0.98      0.90      4660\n",
      "\n",
      "    accuracy                           0.95     19662\n",
      "   macro avg       0.91      0.96      0.93     19662\n",
      "weighted avg       0.95      0.95      0.95     19662\n",
      "\n",
      "floods \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     18219\n",
      "           1       0.77      0.98      0.86      1443\n",
      "\n",
      "    accuracy                           0.98     19662\n",
      "   macro avg       0.89      0.98      0.93     19662\n",
      "weighted avg       0.98      0.98      0.98     19662\n",
      "\n",
      "storm \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     18307\n",
      "           1       0.73      0.97      0.83      1355\n",
      "\n",
      "    accuracy                           0.97     19662\n",
      "   macro avg       0.86      0.97      0.91     19662\n",
      "weighted avg       0.98      0.97      0.97     19662\n",
      "\n",
      "fire \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19520\n",
      "           1       0.63      1.00      0.77       142\n",
      "\n",
      "    accuracy                           1.00     19662\n",
      "   macro avg       0.81      1.00      0.88     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "earthquake \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     18317\n",
      "           1       0.83      0.98      0.90      1345\n",
      "\n",
      "    accuracy                           0.98     19662\n",
      "   macro avg       0.91      0.98      0.95     19662\n",
      "weighted avg       0.99      0.98      0.99     19662\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cold \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     19394\n",
      "           1       0.62      0.99      0.76       268\n",
      "\n",
      "    accuracy                           0.99     19662\n",
      "   macro avg       0.81      0.99      0.88     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "other_weather \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     18949\n",
      "           1       0.62      0.99      0.76       713\n",
      "\n",
      "    accuracy                           0.98     19662\n",
      "   macro avg       0.81      0.98      0.87     19662\n",
      "weighted avg       0.99      0.98      0.98     19662\n",
      "\n",
      "direct_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     17209\n",
      "           1       0.75      0.96      0.84      2453\n",
      "\n",
      "    accuracy                           0.96     19662\n",
      "   macro avg       0.87      0.96      0.91     19662\n",
      "weighted avg       0.96      0.96      0.96     19662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = pipeline.predict(X_train2.reshape(-1,))\n",
    "y_pred2 = pd.DataFrame(y_pred2, columns=Y.columns)\n",
    "y_train2 = pd.DataFrame(y_train2, columns=Y.columns)\n",
    "\n",
    "for col in Y.columns:\n",
    "    print(col, '\\n', classification_report(y_pred2[col], y_train2[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02043826380109566"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_loss(y_train2, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, doesn't seem to be any advantage to it - precision is lower and hamming loss is higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test three different classifiers before tuning hyper params\n",
    "\n",
    "We will test out a \n",
    "1. Multilayer Perceptron - Directly supports multi-label - <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\"> link </a>\n",
    "2. RidgeClassifierCV <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifierCV.html#sklearn.linear_model.RidgeClassifierCV\"> link </a>\n",
    "3. A LinearSVC wrapped in OneVsRestClassifier. In essence, train a separate model to predict for each individual label. <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\"> LinearSVC link </a> and <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html\"> OneVsRest link </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import them\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick and dirty function to look at model results\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def model_compare(y_pred, y_train):\n",
    "    y_pred2 = pd.DataFrame(y_pred, columns=Y.columns)\n",
    "    y_train2 = pd.DataFrame(y_train, columns=Y.columns)\n",
    "\n",
    "    for col in Y.columns:\n",
    "        print(col, '\\n', classification_report(y_pred2[col], y_train2[col]))\n",
    "        \n",
    "        print('\\n', confusion_matrix(y_pred2[col], y_train2[col]))\n",
    "        \n",
    "    print(f\"Hamming Loss: {hamming_loss(y_pred, y_train)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svc = Pipeline([\n",
    "    ('msg_tokenizer', MessageTokenizer()),\n",
    "    # Count Vectorizer with Tokenizer\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    # TF-IDF Transformer\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # classifier - one classifier per label\n",
    "    ('clf', OneVsRestClassifier(SVC(kernel='linear')))\n",
    "])\n",
    "\n",
    "pipeline_svc.fit(X_train, y_train)\n",
    "y_pred_svc = pipeline_svc.predict(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.88      0.80      3830\n",
      "           1       0.97      0.92      0.95     15832\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     19662\n",
      "   macro avg       0.85      0.90      0.87     19662\n",
      "weighted avg       0.92      0.91      0.92     19662\n",
      "\n",
      "\n",
      " [[ 3379   451]\n",
      " [ 1230 14602]]\n",
      "request \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96     17157\n",
      "           1       0.68      0.90      0.77      2505\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     19662\n",
      "   macro avg       0.83      0.92      0.87     19662\n",
      "weighted avg       0.95      0.93      0.94     19662\n",
      "\n",
      "\n",
      " [[16078  1079]\n",
      " [  247  2258]]\n",
      "offer \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19661\n",
      "           1       0.01      1.00      0.02         1\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       0.51      1.00      0.51     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[19582    79]\n",
      " [    0     1]]\n",
      "aid_related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90     12038\n",
      "           1       0.83      0.88      0.85      7624\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     19662\n",
      "   macro avg       0.87      0.88      0.88     19662\n",
      "weighted avg       0.88      0.88      0.88     19662\n",
      "\n",
      "\n",
      " [[10624  1414]\n",
      " [  904  6720]]\n",
      "medical_help \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     18954\n",
      "           1       0.40      0.89      0.55       708\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     19662\n",
      "   macro avg       0.70      0.92      0.76     19662\n",
      "weighted avg       0.97      0.95      0.96     19662\n",
      "\n",
      "\n",
      " [[18002   952]\n",
      " [   81   627]]\n",
      "medical_products \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     19248\n",
      "           1       0.37      0.89      0.52       414\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     19662\n",
      "   macro avg       0.68      0.93      0.75     19662\n",
      "weighted avg       0.98      0.97      0.97     19662\n",
      "\n",
      "\n",
      " [[18620   628]\n",
      " [   45   369]]\n",
      "search_and_rescue \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     19526\n",
      "           1       0.23      0.91      0.36       136\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     19662\n",
      "   macro avg       0.61      0.95      0.68     19662\n",
      "weighted avg       0.99      0.98      0.98     19662\n",
      "\n",
      "\n",
      " [[19104   422]\n",
      " [   12   124]]\n",
      "security \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     19659\n",
      "           1       0.01      1.00      0.02         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     19662\n",
      "   macro avg       0.50      0.99      0.50     19662\n",
      "weighted avg       1.00      0.98      0.99     19662\n",
      "\n",
      "\n",
      " [[19314   345]\n",
      " [    0     3]]\n",
      "military \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     19280\n",
      "           1       0.56      0.96      0.71       382\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     19662\n",
      "   macro avg       0.78      0.97      0.85     19662\n",
      "weighted avg       0.99      0.98      0.99     19662\n",
      "\n",
      "\n",
      " [[18997   283]\n",
      " [   17   365]]\n",
      "water \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     18550\n",
      "           1       0.80      0.90      0.85      1112\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     19662\n",
      "   macro avg       0.90      0.94      0.92     19662\n",
      "weighted avg       0.98      0.98      0.98     19662\n",
      "\n",
      "\n",
      " [[18303   247]\n",
      " [  109  1003]]\n",
      "food \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     17620\n",
      "           1       0.83      0.89      0.86      2042\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     19662\n",
      "   macro avg       0.91      0.93      0.92     19662\n",
      "weighted avg       0.97      0.97      0.97     19662\n",
      "\n",
      "\n",
      " [[17249   371]\n",
      " [  226  1816]]\n",
      "shelter \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     18407\n",
      "           1       0.65      0.90      0.76      1255\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     19662\n",
      "   macro avg       0.82      0.93      0.87     19662\n",
      "weighted avg       0.97      0.96      0.97     19662\n",
      "\n",
      "\n",
      " [[17808   599]\n",
      " [  127  1128]]\n",
      "clothing \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     19453\n",
      "           1       0.59      0.88      0.71       209\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.80      0.94      0.85     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "\n",
      " [[19326   127]\n",
      " [   25   184]]\n",
      "money \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     19488\n",
      "           1       0.36      0.96      0.52       174\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     19662\n",
      "   macro avg       0.68      0.97      0.76     19662\n",
      "weighted avg       0.99      0.98      0.99     19662\n",
      "\n",
      "\n",
      " [[19190   298]\n",
      " [    7   167]]\n",
      "missing_people \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     19615\n",
      "           1       0.21      0.98      0.35        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.60      0.98      0.67     19662\n",
      "weighted avg       1.00      0.99      0.99     19662\n",
      "\n",
      "\n",
      " [[19442   173]\n",
      " [    1    46]]\n",
      "refugees \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     19406\n",
      "           1       0.35      0.92      0.51       256\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     19662\n",
      "   macro avg       0.68      0.95      0.75     19662\n",
      "weighted avg       0.99      0.98      0.98     19662\n",
      "\n",
      "\n",
      " [[18977   429]\n",
      " [   20   236]]\n",
      "death \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     19036\n",
      "           1       0.67      0.93      0.78       626\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     19662\n",
      "   macro avg       0.83      0.96      0.88     19662\n",
      "weighted avg       0.99      0.98      0.98     19662\n",
      "\n",
      "\n",
      " [[18748   288]\n",
      " [   46   580]]\n",
      "other_aid \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94     19166\n",
      "           1       0.18      0.92      0.29       496\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     19662\n",
      "   macro avg       0.59      0.90      0.62     19662\n",
      "weighted avg       0.98      0.89      0.92     19662\n",
      "\n",
      "\n",
      " [[17033  2133]\n",
      " [   42   454]]\n",
      "infrastructure_related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     19603\n",
      "           1       0.04      0.98      0.09        59\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     19662\n",
      "   macro avg       0.52      0.96      0.53     19662\n",
      "weighted avg       1.00      0.94      0.96     19662\n",
      "\n",
      "\n",
      " [[18362  1241]\n",
      " [    1    58]]\n",
      "transport \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     19368\n",
      "           1       0.31      0.94      0.46       294\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     19662\n",
      "   macro avg       0.65      0.95      0.72     19662\n",
      "weighted avg       0.99      0.97      0.98     19662\n",
      "\n",
      "\n",
      " [[18745   623]\n",
      " [   18   276]]\n",
      "buildings \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     19115\n",
      "           1       0.52      0.93      0.67       547\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     19662\n",
      "   macro avg       0.76      0.95      0.83     19662\n",
      "weighted avg       0.98      0.97      0.98     19662\n",
      "\n",
      "\n",
      " [[18644   471]\n",
      " [   39   508]]\n",
      "electricity \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     19455\n",
      "           1       0.48      0.94      0.64       207\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.74      0.97      0.81     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "\n",
      " [[19243   212]\n",
      " [   12   195]]\n",
      "tools \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     19662\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.50      0.50      0.50     19662\n",
      "weighted avg       1.00      0.99      1.00     19662\n",
      "\n",
      "\n",
      " [[19551   111]\n",
      " [    0     0]]\n",
      "hospitals \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     19655\n",
      "           1       0.03      1.00      0.06         7\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.52      0.99      0.53     19662\n",
      "weighted avg       1.00      0.99      0.99     19662\n",
      "\n",
      "\n",
      " [[19443   212]\n",
      " [    0     7]]\n",
      "shops \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19662\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       0.50      0.50      0.50     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[19569    93]\n",
      " [    0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aid_centers \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     19658\n",
      "           1       0.02      1.00      0.03         4\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.51      0.99      0.51     19662\n",
      "weighted avg       1.00      0.99      0.99     19662\n",
      "\n",
      "\n",
      " [[19426   232]\n",
      " [    0     4]]\n",
      "other_infrastructure \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     19641\n",
      "           1       0.02      1.00      0.05        21\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     19662\n",
      "   macro avg       0.51      0.98      0.51     19662\n",
      "weighted avg       1.00      0.96      0.98     19662\n",
      "\n",
      "\n",
      " [[18782   859]\n",
      " [    0    21]]\n",
      "weather_related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95     14810\n",
      "           1       0.82      0.92      0.87      4852\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     19662\n",
      "   macro avg       0.90      0.93      0.91     19662\n",
      "weighted avg       0.94      0.93      0.93     19662\n",
      "\n",
      "\n",
      " [[13829   981]\n",
      " [  380  4472]]\n",
      "floods \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     18637\n",
      "           1       0.61      0.95      0.74      1025\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     19662\n",
      "   macro avg       0.80      0.96      0.86     19662\n",
      "weighted avg       0.98      0.97      0.97     19662\n",
      "\n",
      "\n",
      " [[18015   622]\n",
      " [   51   974]]\n",
      "storm \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     18059\n",
      "           1       0.78      0.89      0.83      1603\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     19662\n",
      "   macro avg       0.89      0.93      0.91     19662\n",
      "weighted avg       0.97      0.97      0.97     19662\n",
      "\n",
      "\n",
      " [[17664   395]\n",
      " [  177  1426]]\n",
      "fire \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     19572\n",
      "           1       0.41      0.98      0.58        90\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.71      0.99      0.79     19662\n",
      "weighted avg       1.00      0.99      0.99     19662\n",
      "\n",
      "\n",
      " [[19447   125]\n",
      " [    2    88]]\n",
      "earthquake \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     17997\n",
      "           1       0.85      0.93      0.89      1665\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     19662\n",
      "   macro avg       0.92      0.96      0.94     19662\n",
      "weighted avg       0.98      0.98      0.98     19662\n",
      "\n",
      "\n",
      " [[17717   280]\n",
      " [  121  1544]]\n",
      "cold \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     19415\n",
      "           1       0.56      0.93      0.70       247\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     19662\n",
      "   macro avg       0.78      0.96      0.85     19662\n",
      "weighted avg       0.99      0.99      0.99     19662\n",
      "\n",
      "\n",
      " [[19237   178]\n",
      " [   18   229]]\n",
      "other_weather \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     19441\n",
      "           1       0.20      0.95      0.33       221\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     19662\n",
      "   macro avg       0.60      0.95      0.65     19662\n",
      "weighted avg       0.99      0.96      0.97     19662\n",
      "\n",
      "\n",
      " [[18602   839]\n",
      " [   12   209]]\n",
      "direct_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94     17050\n",
      "           1       0.60      0.87      0.71      2612\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     19662\n",
      "   macro avg       0.79      0.89      0.83     19662\n",
      "weighted avg       0.93      0.91      0.91     19662\n",
      "\n",
      "\n",
      " [[15524  1526]\n",
      " [  339  2273]]\n",
      "Hamming Loss: 0.03433308630134996\n"
     ]
    }
   ],
   "source": [
    "model_compare(y_pred_svc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwilliams1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4614\n",
      "           1       1.00      1.00      1.00     15048\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      0.99      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[ 4577    37]\n",
      " [   32 15016]]\n",
      "request \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16339\n",
      "           1       0.99      1.00      1.00      3323\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[16316    23]\n",
      " [    9  3314]]\n",
      "offer \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19583\n",
      "           1       0.99      1.00      0.99        79\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       0.99      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[19582     1]\n",
      " [    0    79]]\n",
      "aid_related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     11525\n",
      "           1       1.00      1.00      1.00      8137\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[11513    12]\n",
      " [   15  8122]]\n",
      "medical_help \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18086\n",
      "           1       1.00      1.00      1.00      1576\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[18080     6]\n",
      " [    3  1573]]\n",
      "medical_products \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18671\n",
      "           1       0.99      1.00      1.00       991\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[18665     6]\n",
      " [    0   991]]\n",
      "search_and_rescue \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19115\n",
      "           1       1.00      1.00      1.00       547\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[19114     1]\n",
      " [    2   545]]\n",
      "security \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19318\n",
      "           1       0.99      1.00      0.99       344\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       0.99      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[19313     5]\n",
      " [    1   343]]\n",
      "military \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19016\n",
      "           1       1.00      1.00      1.00       646\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[19014     2]\n",
      " [    0   646]]\n",
      "water \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18411\n",
      "           1       1.00      1.00      1.00      1251\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[18411     0]\n",
      " [    1  1250]]\n",
      "food \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     17474\n",
      "           1       1.00      1.00      1.00      2188\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[17474     0]\n",
      " [    1  2187]]\n",
      "shelter \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     17933\n",
      "           1       1.00      1.00      1.00      1729\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[17933     0]\n",
      " [    2  1727]]\n",
      "clothing \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19352\n",
      "           1       1.00      1.00      1.00       310\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[19351     1]\n",
      " [    0   310]]\n",
      "money \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19197\n",
      "           1       1.00      1.00      1.00       465\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[19197     0]\n",
      " [    0   465]]\n",
      "missing_people \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19444\n",
      "           1       1.00      1.00      1.00       218\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[19443     1]\n",
      " [    0   218]]\n",
      "refugees \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18998\n",
      "           1       1.00      1.00      1.00       664\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[18996     2]\n",
      " [    1   663]]\n",
      "death \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18793\n",
      "           1       1.00      1.00      1.00       869\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[18792     1]\n",
      " [    2   867]]\n",
      "other_aid \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     17071\n",
      "           1       1.00      1.00      1.00      2591\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[17063     8]\n",
      " [   12  2579]]\n",
      "infrastructure_related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18364\n",
      "           1       1.00      1.00      1.00      1298\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[18362     2]\n",
      " [    1  1297]]\n",
      "transport \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18764\n",
      "           1       1.00      1.00      1.00       898\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[18760     4]\n",
      " [    3   895]]\n",
      "buildings \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18684\n",
      "           1       1.00      1.00      1.00       978\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[18682     2]\n",
      " [    1   977]]\n",
      "electricity \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19255\n",
      "           1       1.00      1.00      1.00       407\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[19255     0]\n",
      " [    0   407]]\n",
      "tools \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19552\n",
      "           1       0.99      1.00      1.00       110\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [[19551     1]\n",
      " [    0   110]]\n",
      "hospitals \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19443\n",
      "           1       1.00      1.00      1.00       219\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[19443     0]\n",
      " [    0   219]]\n",
      "shops \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19569\n",
      "           1       1.00      1.00      1.00        93\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[19569     0]\n",
      " [    0    93]]\n",
      "aid_centers \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19426\n",
      "           1       1.00      1.00      1.00       236\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[19426     0]\n",
      " [    0   236]]\n",
      "other_infrastructure \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18783\n",
      "           1       1.00      1.00      1.00       879\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[18781     2]\n",
      " [    1   878]]\n",
      "weather_related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14209\n",
      "           1       1.00      1.00      1.00      5453\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[14203     6]\n",
      " [    6  5447]]\n",
      "floods \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18066\n",
      "           1       1.00      1.00      1.00      1596\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[18063     3]\n",
      " [    3  1593]]\n",
      "storm \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     17840\n",
      "           1       1.00      1.00      1.00      1822\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[17839     1]\n",
      " [    2  1820]]\n",
      "fire \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19449\n",
      "           1       1.00      1.00      1.00       213\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[19449     0]\n",
      " [    0   213]]\n",
      "earthquake \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     17834\n",
      "           1       1.00      1.00      1.00      1828\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[17833     1]\n",
      " [    5  1823]]\n",
      "cold \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19256\n",
      "           1       1.00      1.00      1.00       406\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[19255     1]\n",
      " [    0   406]]\n",
      "other_weather \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18618\n",
      "           1       1.00      1.00      1.00      1044\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[18614     4]\n",
      " [    0  1044]]\n",
      "direct_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     15862\n",
      "           1       1.00      1.00      1.00      3800\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     19662\n",
      "   macro avg       1.00      1.00      1.00     19662\n",
      "weighted avg       1.00      1.00      1.00     19662\n",
      "\n",
      "\n",
      " [[15849    13]\n",
      " [   14  3786]]\n",
      "Hamming Loss: 0.0003821730095761222\n"
     ]
    }
   ],
   "source": [
    "pipeline_mlp = Pipeline([\n",
    "    ('msg_tokenizer', MessageTokenizer()),\n",
    "    # Count Vectorizer with Tokenizer\n",
    "    ('count_vec', CountVectorizer()),\n",
    "    # TF-IDF Transformer\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # classifier - one classifier per label\n",
    "    ('clf', MLPClassifier())\n",
    "])\n",
    "\n",
    "pipeline_mlp.fit(X_train, y_train)\n",
    "y_pred_mlp = pipeline_mlp.predict(X_train)\n",
    "\n",
    "model_compare(y_pred_mlp, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmmmmmmmmmm. Looks like that neural net is way overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8% of labels are predicted incorrectly with RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVC Classifier is not as good at distinguishing between the majority and the minority classes. Accuracy on the individual labels is worse, and Hamming score is worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune the grid with hamming loss  - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hamming_loss.html\n",
    "# make a custom scorer https://scikit-learn.org/stable/modules/model_evaluation.html#scoring\n",
    "from sklearn.metrics import hamming_loss, make_scorer\n",
    "hamming_scorer = make_scorer(hamming_loss, greater_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DenseTranformer class to make sure the output is correct for the GaussianNB\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_nb = Pipeline([\n",
    "    ('msg_tokenizer', MessageTokenizer()),\n",
    "    # Count Vectorizer with Tokenizer\n",
    "    ('count_vec', CountVectorizer(tokenizer=tokenize)),\n",
    "    # TF-IDF Transformer\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # make sure the output is dense, not sparse - needed for GaussianNB\n",
    "    ('dense', DenseTransformer()),\n",
    "    # classifier - one classifier per label\n",
    "    ('clf', MultiOutputClassifier(estimator=GaussianNB()))\n",
    "])\n",
    "\n",
    "pipeline_nb.fit(X_train.values, y_train)\n",
    "y_pred_nb = pipeline_nb.predict(X_train.values)\n",
    "\n",
    "model_compare(y_pred_nb, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing to go with the RandomForest model because it seems to yield the best results on training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomizedSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ae2fec35b5c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhamming_scorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomizedSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "search_params = {\n",
    "    'msg_tokenizer__remove_stops': [False, True],\n",
    "    'msg_tokenizer__lemmatize': [False, True],\n",
    "    'count_vec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'count_vec__max_features': [None, 100, 500, 1000],\n",
    "    'tfidf__norm': [None, 'l1', 'l2'],\n",
    "    'tfidf__use_idf': [False, True],\n",
    "    'tfidf__smooth_idf': [False, True],\n",
    "    'clf__estimator__n_estimators': [10, 100, 500],\n",
    "    'clf__estimator__max_depth': [None, 50, 100, 500],\n",
    "    'clf__estimator__bootstrap': [True, False],\n",
    "    'clf__estimator__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "cv = RandomizedSearchCV(pipeline, search_params, n_iter=5, n_jobs=-1, scoring=hamming_scorer)\n",
    "search = cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = RandomizedSearchCV(pipeline, search_params, n_iter=10, n_jobs=-1, scoring=hamming_score)\n",
    "search2 = cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
